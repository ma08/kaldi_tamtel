# nnet3-show-progress --use-gpu=no --verbose=2 telugu_exp/chain_cleaned_1d/tdnn1d_sp/109.mdl telugu_exp/chain_cleaned_1d/tdnn1d_sp/110.mdl 
# Started at Wed Jul 20 11:24:50 EDT 2022
#
nnet3-show-progress --use-gpu=no --verbose=2 telugu_exp/chain_cleaned_1d/tdnn1d_sp/109.mdl telugu_exp/chain_cleaned_1d/tdnn1d_sp/110.mdl 
LOG (nnet3-show-progress[5.5.1035~1-3dd90]:SelectGpuId():cu-device.cc:168) Manually selected to compute on CPU.
VLOG[1] (nnet3-show-progress[5.5.1035~1-3dd90]:main():nnet3-show-progress.cc:136) Printing info for the difference between the neural nets: left-context: 28
right-context: 28
num-parameters: 9032208
modulus: 1
input-node name=ivector dim=100
input-node name=input dim=40
component-node name=lda component=lda input=Append(Offset(input, -1), input, Offset(input, 1), ReplaceIndex(ivector, t, 0)) input-dim=220 output-dim=220
component-node name=tdnn1.affine component=tdnn1.affine input=lda input-dim=220 output-dim=1024
component-node name=tdnn1.relu component=tdnn1.relu input=tdnn1.affine input-dim=1024 output-dim=1024
component-node name=tdnn1.batchnorm component=tdnn1.batchnorm input=tdnn1.relu input-dim=1024 output-dim=1024
component-node name=tdnn1.dropout component=tdnn1.dropout input=tdnn1.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf2.linear component=tdnnf2.linear input=tdnn1.dropout input-dim=1024 output-dim=128
component-node name=tdnnf2.affine component=tdnnf2.affine input=tdnnf2.linear input-dim=128 output-dim=1024
component-node name=tdnnf2.relu component=tdnnf2.relu input=tdnnf2.affine input-dim=1024 output-dim=1024
component-node name=tdnnf2.batchnorm component=tdnnf2.batchnorm input=tdnnf2.relu input-dim=1024 output-dim=1024
component-node name=tdnnf2.dropout component=tdnnf2.dropout input=tdnnf2.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf2.noop component=tdnnf2.noop input=Sum(Scale(0.66, tdnn1.dropout), tdnnf2.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf3.linear component=tdnnf3.linear input=tdnnf2.noop input-dim=1024 output-dim=128
component-node name=tdnnf3.affine component=tdnnf3.affine input=tdnnf3.linear input-dim=128 output-dim=1024
component-node name=tdnnf3.relu component=tdnnf3.relu input=tdnnf3.affine input-dim=1024 output-dim=1024
component-node name=tdnnf3.batchnorm component=tdnnf3.batchnorm input=tdnnf3.relu input-dim=1024 output-dim=1024
component-node name=tdnnf3.dropout component=tdnnf3.dropout input=tdnnf3.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf3.noop component=tdnnf3.noop input=Sum(Scale(0.66, tdnnf2.noop), tdnnf3.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf4.linear component=tdnnf4.linear input=tdnnf3.noop input-dim=1024 output-dim=128
component-node name=tdnnf4.affine component=tdnnf4.affine input=tdnnf4.linear input-dim=128 output-dim=1024
component-node name=tdnnf4.relu component=tdnnf4.relu input=tdnnf4.affine input-dim=1024 output-dim=1024
component-node name=tdnnf4.batchnorm component=tdnnf4.batchnorm input=tdnnf4.relu input-dim=1024 output-dim=1024
component-node name=tdnnf4.dropout component=tdnnf4.dropout input=tdnnf4.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf4.noop component=tdnnf4.noop input=Sum(Scale(0.66, tdnnf3.noop), tdnnf4.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf5.linear component=tdnnf5.linear input=tdnnf4.noop input-dim=1024 output-dim=128
component-node name=tdnnf5.affine component=tdnnf5.affine input=tdnnf5.linear input-dim=128 output-dim=1024
component-node name=tdnnf5.relu component=tdnnf5.relu input=tdnnf5.affine input-dim=1024 output-dim=1024
component-node name=tdnnf5.batchnorm component=tdnnf5.batchnorm input=tdnnf5.relu input-dim=1024 output-dim=1024
component-node name=tdnnf5.dropout component=tdnnf5.dropout input=tdnnf5.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf5.noop component=tdnnf5.noop input=Sum(Scale(0.66, tdnnf4.noop), tdnnf5.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf6.linear component=tdnnf6.linear input=tdnnf5.noop input-dim=1024 output-dim=128
component-node name=tdnnf6.affine component=tdnnf6.affine input=tdnnf6.linear input-dim=128 output-dim=1024
component-node name=tdnnf6.relu component=tdnnf6.relu input=tdnnf6.affine input-dim=1024 output-dim=1024
component-node name=tdnnf6.batchnorm component=tdnnf6.batchnorm input=tdnnf6.relu input-dim=1024 output-dim=1024
component-node name=tdnnf6.dropout component=tdnnf6.dropout input=tdnnf6.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf6.noop component=tdnnf6.noop input=Sum(Scale(0.66, tdnnf5.noop), tdnnf6.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf7.linear component=tdnnf7.linear input=tdnnf6.noop input-dim=1024 output-dim=128
component-node name=tdnnf7.affine component=tdnnf7.affine input=tdnnf7.linear input-dim=128 output-dim=1024
component-node name=tdnnf7.relu component=tdnnf7.relu input=tdnnf7.affine input-dim=1024 output-dim=1024
component-node name=tdnnf7.batchnorm component=tdnnf7.batchnorm input=tdnnf7.relu input-dim=1024 output-dim=1024
component-node name=tdnnf7.dropout component=tdnnf7.dropout input=tdnnf7.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf7.noop component=tdnnf7.noop input=Sum(Scale(0.66, tdnnf6.noop), tdnnf7.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf8.linear component=tdnnf8.linear input=tdnnf7.noop input-dim=1024 output-dim=128
component-node name=tdnnf8.affine component=tdnnf8.affine input=tdnnf8.linear input-dim=128 output-dim=1024
component-node name=tdnnf8.relu component=tdnnf8.relu input=tdnnf8.affine input-dim=1024 output-dim=1024
component-node name=tdnnf8.batchnorm component=tdnnf8.batchnorm input=tdnnf8.relu input-dim=1024 output-dim=1024
component-node name=tdnnf8.dropout component=tdnnf8.dropout input=tdnnf8.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf8.noop component=tdnnf8.noop input=Sum(Scale(0.66, tdnnf7.noop), tdnnf8.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf9.linear component=tdnnf9.linear input=tdnnf8.noop input-dim=1024 output-dim=128
component-node name=tdnnf9.affine component=tdnnf9.affine input=tdnnf9.linear input-dim=128 output-dim=1024
component-node name=tdnnf9.relu component=tdnnf9.relu input=tdnnf9.affine input-dim=1024 output-dim=1024
component-node name=tdnnf9.batchnorm component=tdnnf9.batchnorm input=tdnnf9.relu input-dim=1024 output-dim=1024
component-node name=tdnnf9.dropout component=tdnnf9.dropout input=tdnnf9.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf9.noop component=tdnnf9.noop input=Sum(Scale(0.66, tdnnf8.noop), tdnnf9.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf10.linear component=tdnnf10.linear input=tdnnf9.noop input-dim=1024 output-dim=128
component-node name=tdnnf10.affine component=tdnnf10.affine input=tdnnf10.linear input-dim=128 output-dim=1024
component-node name=tdnnf10.relu component=tdnnf10.relu input=tdnnf10.affine input-dim=1024 output-dim=1024
component-node name=tdnnf10.batchnorm component=tdnnf10.batchnorm input=tdnnf10.relu input-dim=1024 output-dim=1024
component-node name=tdnnf10.dropout component=tdnnf10.dropout input=tdnnf10.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf10.noop component=tdnnf10.noop input=Sum(Scale(0.66, tdnnf9.noop), tdnnf10.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf11.linear component=tdnnf11.linear input=tdnnf10.noop input-dim=1024 output-dim=128
component-node name=tdnnf11.affine component=tdnnf11.affine input=tdnnf11.linear input-dim=128 output-dim=1024
component-node name=tdnnf11.relu component=tdnnf11.relu input=tdnnf11.affine input-dim=1024 output-dim=1024
component-node name=tdnnf11.batchnorm component=tdnnf11.batchnorm input=tdnnf11.relu input-dim=1024 output-dim=1024
component-node name=tdnnf11.dropout component=tdnnf11.dropout input=tdnnf11.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf11.noop component=tdnnf11.noop input=Sum(Scale(0.66, tdnnf10.noop), tdnnf11.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf12.linear component=tdnnf12.linear input=tdnnf11.noop input-dim=1024 output-dim=128
component-node name=tdnnf12.affine component=tdnnf12.affine input=tdnnf12.linear input-dim=128 output-dim=1024
component-node name=tdnnf12.relu component=tdnnf12.relu input=tdnnf12.affine input-dim=1024 output-dim=1024
component-node name=tdnnf12.batchnorm component=tdnnf12.batchnorm input=tdnnf12.relu input-dim=1024 output-dim=1024
component-node name=tdnnf12.dropout component=tdnnf12.dropout input=tdnnf12.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf12.noop component=tdnnf12.noop input=Sum(Scale(0.66, tdnnf11.noop), tdnnf12.dropout) input-dim=1024 output-dim=1024
component-node name=tdnnf13.linear component=tdnnf13.linear input=tdnnf12.noop input-dim=1024 output-dim=128
component-node name=tdnnf13.affine component=tdnnf13.affine input=tdnnf13.linear input-dim=128 output-dim=1024
component-node name=tdnnf13.relu component=tdnnf13.relu input=tdnnf13.affine input-dim=1024 output-dim=1024
component-node name=tdnnf13.batchnorm component=tdnnf13.batchnorm input=tdnnf13.relu input-dim=1024 output-dim=1024
component-node name=tdnnf13.dropout component=tdnnf13.dropout input=tdnnf13.batchnorm input-dim=1024 output-dim=1024
component-node name=tdnnf13.noop component=tdnnf13.noop input=Sum(Scale(0.66, tdnnf12.noop), tdnnf13.dropout) input-dim=1024 output-dim=1024
component-node name=prefinal-l component=prefinal-l input=tdnnf13.noop input-dim=1024 output-dim=256
component-node name=prefinal-chain.affine component=prefinal-chain.affine input=prefinal-l input-dim=256 output-dim=1024
component-node name=prefinal-chain.relu component=prefinal-chain.relu input=prefinal-chain.affine input-dim=1024 output-dim=1024
component-node name=prefinal-chain.batchnorm1 component=prefinal-chain.batchnorm1 input=prefinal-chain.relu input-dim=1024 output-dim=1024
component-node name=prefinal-chain.linear component=prefinal-chain.linear input=prefinal-chain.batchnorm1 input-dim=1024 output-dim=256
component-node name=prefinal-chain.batchnorm2 component=prefinal-chain.batchnorm2 input=prefinal-chain.linear input-dim=256 output-dim=256
component-node name=output.affine component=output.affine input=prefinal-chain.batchnorm2 input-dim=256 output-dim=2824
output-node name=output input=output.affine dim=2824 objective=linear
component-node name=prefinal-xent.affine component=prefinal-xent.affine input=prefinal-l input-dim=256 output-dim=1024
component-node name=prefinal-xent.relu component=prefinal-xent.relu input=prefinal-xent.affine input-dim=1024 output-dim=1024
component-node name=prefinal-xent.batchnorm1 component=prefinal-xent.batchnorm1 input=prefinal-xent.relu input-dim=1024 output-dim=1024
component-node name=prefinal-xent.linear component=prefinal-xent.linear input=prefinal-xent.batchnorm1 input-dim=1024 output-dim=256
component-node name=prefinal-xent.batchnorm2 component=prefinal-xent.batchnorm2 input=prefinal-xent.linear input-dim=256 output-dim=256
component-node name=output-xent.affine component=output-xent.affine input=prefinal-xent.batchnorm2 input-dim=256 output-dim=2824
component-node name=output-xent.log-softmax component=output-xent.log-softmax input=output-xent.affine input-dim=2824 output-dim=2824
output-node name=output-xent input=output-xent.log-softmax dim=2824 objective=linear
component name=lda type=FixedAffineComponent, input-dim=220, output-dim=220, linear-params-rms=0.005753, bias-{mean,stddev}=-0.001002,0.01283
component name=tdnn1.affine type=NaturalGradientAffineComponent, input-dim=220, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, linear-params-rms=0.003591, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.03,0.03,0.04 0.04,0.04,0.05,0.06,0.06 0.07,0.07,0.08,0.09), mean=0.0523, stddev=0.0103], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.06,0.06,0.07 0.07,0.08,0.10,0.12,0.15 0.21,0.22,0.23,0.27), mean=0.108, stddev=0.0389], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.04,0.04 0.05,0.06,0.09,0.14,0.17 0.21,0.24,0.25,0.28), mean=0.103, stddev=0.0511], bias-{mean,stddev}=-0.0001289,0.003089, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha=4
component name=tdnn1.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05
component name=tdnn1.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=229.426, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-1.3,-0.77,-0.70,-0.53 -0.38,-0.23,-0.006,0.25,0.44 0.56,0.73,0.80,1.2), mean=0.00776, stddev=0.323], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0,0 0.04,0.07,0.08,0.11), mean=0.00386, stddev=0.0146]
component name=tdnn1.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf2.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-1,0, linear-params-rms=0.002186, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.09,0.09,0.09,0.09 0.09,0.09,0.10,0.10,0.11 0.11,0.11,0.11,0.11), mean=0.0988, stddev=0.00499], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.02 0.02,0.02,0.02,0.03,0.03 0.03,0.03,0.03,0.04), mean=0.0242, stddev=0.00516], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.04 0.04,0.05,0.09,0.13,0.15 0.16,0.17,0.18,0.18), mean=0.0906, stddev=0.0397], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf2.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,1, linear-params-rms=0.002201, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.03,0.03,0.03 0.03,0.03,0.03,0.04,0.04 0.04,0.04,0.05,0.05), mean=0.0349, stddev=0.00438], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.06,0.06,0.06,0.06 0.07,0.07,0.07,0.07,0.07 0.08,0.08,0.08,0.08), mean=0.0703, stddev=0.00323], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.008,0.009,0.01,0.01 0.01,0.02,0.05,0.10,0.12 0.14,0.15,0.16,0.17), mean=0.0565, stddev=0.042], bias-{mean,stddev}=-0.0002829,0.002073, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf2.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, count=1.78e+05, self-repaired-proportion=0, value-avg=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.03,-0.01,-0.01,-0.005 0.002,0.01,0.03,0.05,0.05 0.06,0.07,0.08,0.09), mean=0.0277, stddev=0.0206], deriv-avg=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.35,-0.18,-0.12,-0.02 0.07,0.17,0.37,0.56,0.67 0.76,0.86,0.93,1.2), mean=0.368, stddev=0.237], oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.08,0.11 0.13,0.16,0.18,0.28), mean=0.0326, stddev=0.0495], oderiv-count=105792
component name=tdnnf2.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=229.426, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.86,-0.63,-0.53,-0.43 -0.30,-0.18,0.05,0.28,0.38 0.48,0.59,0.64,0.95), mean=0.0441, stddev=0.273], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.08,0.13 0.16,0.19,0.22,0.33), mean=0.0313, stddev=0.0571]
component name=tdnnf2.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf2.noop type=NoOpComponent, dim=1024
component name=tdnnf3.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-1,0, linear-params-rms=0.001871, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.07,0.08,0.08,0.08 0.08,0.08,0.08,0.09,0.09 0.09,0.09,0.09,0.09), mean=0.0846, stddev=0.00358], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.02 0.02,0.02,0.02,0.02,0.02 0.03,0.03,0.03,0.03), mean=0.021, stddev=0.003], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.04,0.05,0.07,0.11,0.13 0.13,0.14,0.14,0.15), mean=0.0782, stddev=0.0324], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf3.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,1, linear-params-rms=0.001906, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.03,0.03,0.03,0.03,0.03 0.04,0.04,0.04,0.04), mean=0.0303, stddev=0.0035], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.06,0.06 0.06,0.06,0.06,0.06,0.06 0.06,0.07,0.07,0.07), mean=0.0609, stddev=0.00251], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.02,0.02,0.04,0.08,0.10 0.12,0.13,0.13,0.14), mean=0.051, stddev=0.0335], bias-{mean,stddev}=-0.0001594,0.002721, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf3.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05
component name=tdnnf3.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=229.426, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-1.2,-0.84,-0.72,-0.52 -0.38,-0.18,0.15,0.45,0.64 0.77,0.94,1.0,1.6), mean=0.139, stddev=0.399], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.11,0.19 0.23,0.28,0.30,0.37), mean=0.0453, stddev=0.0836]
component name=tdnnf3.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf3.noop type=NoOpComponent, dim=1024
component name=tdnnf4.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-1,0, linear-params-rms=0.001694, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.07,0.07,0.07,0.07 0.07,0.07,0.08,0.08,0.08 0.08,0.08,0.08,0.09), mean=0.0766, stddev=0.00347], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.02 0.02,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.03), mean=0.0191, stddev=0.00206], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.03,0.04,0.07,0.10,0.11 0.12,0.12,0.13,0.13), mean=0.071, stddev=0.029], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf4.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,1, linear-params-rms=0.001775, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.03,0.03,0.03,0.03 0.03,0.03,0.04,0.04), mean=0.0282, stddev=0.00296], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.06,0.06,0.06 0.06,0.06,0.06,0.06), mean=0.0568, stddev=0.00245], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.02,0.02,0.04,0.08,0.09 0.11,0.12,0.13,0.13), mean=0.0479, stddev=0.0305], bias-{mean,stddev}=-6.366e-05,0.002142, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf4.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, count=2.63e+04, self-repaired-proportion=0, value-avg=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.12,-0.06,-0.04,-0.02 -0.002,0.02,0.08,0.12,0.15 0.17,0.19,0.21,0.27), mean=0.0738, stddev=0.0585], deriv-avg=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.76,-0.58,-0.44,-0.23 -0.08,0.12,0.44,0.79,0.92 1.1,1.3,1.3,1.9), mean=0.44, stddev=0.4], oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.06,0.08 0.09,0.11,0.12,0.17), mean=0.0262, stddev=0.0348], oderiv-count=40256
component name=tdnnf4.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-1.0,-0.84,-0.76,-0.63 -0.45,-0.23,0.11,0.42,0.60 0.74,0.91,1.0,1.6), mean=0.0937, stddev=0.406], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.15,0.24 0.29,0.35,0.37,0.53), mean=0.0597, stddev=0.106]
component name=tdnnf4.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf4.noop type=NoOpComponent, dim=1024
component name=tdnnf5.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=0, linear-params-rms=0.001785, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.06,0.06,0.06 0.06,0.06,0.06,0.07), mean=0.0571, stddev=0.00285], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.02,0.02,0.02 0.02,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.03), mean=0.0201, stddev=0.00184], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.03 0.03,0.03,0.05,0.07,0.08 0.09,0.09,0.10,0.10), mean=0.0533, stddev=0.0206], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf5.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0, linear-params-rms=0.001931, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.004,0.01,0.01,0.02 0.02,0.02,0.02,0.02,0.03 0.03,0.03,0.03,0.03), mean=0.0216, stddev=0.00349], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.06,0.06,0.06 0.06,0.06,0.06,0.06,0.07 0.07,0.07,0.07,0.07), mean=0.0617, stddev=0.00312], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.03,0.04,0.05,0.08,0.09 0.10,0.10,0.10,0.11), mean=0.0581, stddev=0.0211], bias-{mean,stddev}=-0.0001967,0.002104, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf5.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, count=1.01e+05, self-repaired-proportion=-0.03125, value-avg=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.03,-0.01,-0.009,-0.005 -0.002,0.002,0.01,0.03,0.03 0.04,0.05,0.05,0.06), mean=0.0145, stddev=0.0141], deriv-avg=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.84,-0.26,-0.18,-0.09 -0.02,0.07,0.26,0.46,0.55 0.65,0.72,0.78,0.99), mean=0.264, stddev=0.227]
component name=tdnnf5.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.82,-0.51,-0.42,-0.33 -0.25,-0.13,0.07,0.28,0.40 0.49,0.63,0.67,0.85), mean=0.072, stddev=0.251], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0,0.07 0.11,0.14,0.17,0.20), mean=0.0146, stddev=0.0373]
component name=tdnnf5.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf5.noop type=NoOpComponent, dim=1024
component name=tdnnf6.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-3,0, linear-params-rms=0.001728, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.07,0.07,0.07,0.07 0.07,0.07,0.08,0.08,0.08 0.08,0.08,0.09,0.09), mean=0.0781, stddev=0.00325], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.02 0.02,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.03), mean=0.0194, stddev=0.0022], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.04 0.04,0.05,0.07,0.10,0.11 0.12,0.12,0.12,0.13), mean=0.0737, stddev=0.0262], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf6.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,3, linear-params-rms=0.001876, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.03 0.03,0.03,0.03,0.03,0.03 0.03,0.04,0.04,0.04), mean=0.0299, stddev=0.00288], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.06,0.06,0.06 0.06,0.06,0.06,0.06,0.06 0.06,0.07,0.07,0.07), mean=0.06, stddev=0.00259], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.03,0.05,0.08,0.10 0.11,0.11,0.12,0.12), mean=0.0534, stddev=0.0275], bias-{mean,stddev}=-0.0002149,0.002183, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf6.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.06,0.08 0.10,0.11,0.12,0.19), mean=0.0294, stddev=0.0354], oderiv-count=66624
component name=tdnnf6.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.81,-0.56,-0.51,-0.38 -0.25,-0.11,0.13,0.43,0.57 0.68,0.81,0.91,1.4), mean=0.153, stddev=0.321], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.15,0.21 0.25,0.30,0.33,0.58), mean=0.0555, stddev=0.0938]
component name=tdnnf6.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf6.noop type=NoOpComponent, dim=1024
component name=tdnnf7.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-3,0, linear-params-rms=0.001653, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.07,0.07,0.07,0.07 0.07,0.07,0.07,0.08,0.08 0.08,0.08,0.08,0.08), mean=0.0748, stddev=0.00292], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.02 0.02,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.03), mean=0.0186, stddev=0.00178], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.04 0.04,0.05,0.07,0.09,0.10 0.11,0.11,0.11,0.12), mean=0.0711, stddev=0.0234], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf7.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,3, linear-params-rms=0.001799, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.03,0.03,0.03,0.03,0.03 0.03,0.04,0.04,0.04), mean=0.0286, stddev=0.00298], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.06,0.06,0.06,0.06 0.06,0.06,0.06,0.06), mean=0.0575, stddev=0.00247], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.03,0.04,0.08,0.09 0.10,0.11,0.11,0.12), mean=0.0512, stddev=0.0263], bias-{mean,stddev}=-0.0002816,0.002005, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf7.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.05,0.07 0.09,0.10,0.12,0.17), mean=0.022, stddev=0.0321], oderiv-count=51392
component name=tdnnf7.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.88,-0.58,-0.47,-0.38 -0.27,-0.12,0.13,0.38,0.49 0.60,0.71,0.82,1.1), mean=0.125, stddev=0.3], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.15,0.20 0.24,0.29,0.31,0.43), mean=0.0543, stddev=0.0904]
component name=tdnnf7.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf7.noop type=NoOpComponent, dim=1024
component name=tdnnf8.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-3,0, linear-params-rms=0.001582, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.06,0.07,0.07,0.07 0.07,0.07,0.07,0.07,0.07 0.08,0.08,0.08,0.08), mean=0.0716, stddev=0.00266], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.02 0.02,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.02), mean=0.0178, stddev=0.00164], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.04 0.04,0.05,0.07,0.09,0.10 0.10,0.11,0.11,0.11), mean=0.0682, stddev=0.0217], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf8.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,3, linear-params-rms=0.001745, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.03,0.03,0.03,0.03 0.03,0.03,0.03,0.04), mean=0.0278, stddev=0.00291], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.06,0.06,0.06 0.06,0.06,0.06,0.06), mean=0.0558, stddev=0.0022], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.02,0.04,0.07,0.09 0.10,0.11,0.11,0.12), mean=0.0494, stddev=0.0261], bias-{mean,stddev}=-9.428e-05,0.001918, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf8.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.05,0.06 0.07,0.09,0.11,0.16), mean=0.0203, stddev=0.0289], oderiv-count=65600
component name=tdnnf8.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.91,-0.50,-0.41,-0.31 -0.22,-0.08,0.15,0.43,0.56 0.65,0.76,0.81,1.4), mean=0.166, stddev=0.3], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.13,0.20 0.25,0.29,0.31,0.37), mean=0.0517, stddev=0.0901]
component name=tdnnf8.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf8.noop type=NoOpComponent, dim=1024
component name=tdnnf9.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-3,0, linear-params-rms=0.001554, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.06,0.06,0.06,0.07 0.07,0.07,0.07,0.07,0.07 0.07,0.08,0.08,0.08), mean=0.0703, stddev=0.00276], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.02,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.02), mean=0.0175, stddev=0.00176], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.04,0.05,0.07,0.09,0.10 0.10,0.11,0.11,0.11), mean=0.067, stddev=0.0215], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf9.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,3, linear-params-rms=0.00169, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.02,0.03,0.03,0.03 0.03,0.03,0.03,0.04), mean=0.0269, stddev=0.00293], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.05,0.06,0.06 0.06,0.06,0.06,0.06), mean=0.054, stddev=0.00205], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.02,0.02,0.02 0.02,0.02,0.04,0.07,0.09 0.10,0.10,0.11,0.12), mean=0.0475, stddev=0.0259], bias-{mean,stddev}=-0.0001453,0.0018, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf9.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05
component name=tdnnf9.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.77,-0.55,-0.47,-0.35 -0.25,-0.10,0.16,0.40,0.55 0.68,0.78,0.87,1.3), mean=0.155, stddev=0.31], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.15,0.23 0.28,0.35,0.40,0.66), mean=0.0622, stddev=0.106]
component name=tdnnf9.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf9.noop type=NoOpComponent, dim=1024
component name=tdnnf10.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-3,0, linear-params-rms=0.001511, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.06,0.06,0.06,0.06 0.07,0.07,0.07,0.07,0.07 0.07,0.07,0.07,0.07), mean=0.0683, stddev=0.00244], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.009,0.01,0.01,0.01 0.01,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.02), mean=0.017, stddev=0.0019], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.04,0.04,0.06,0.09,0.09 0.10,0.10,0.10,0.11), mean=0.0652, stddev=0.0208], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf10.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,3, linear-params-rms=0.001636, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.02,0.03,0.03,0.03 0.03,0.03,0.03,0.04), mean=0.026, stddev=0.00278], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.05,0.05,0.05 0.06,0.06,0.06,0.06), mean=0.0523, stddev=0.00185], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.02 0.02,0.02,0.04,0.07,0.08 0.09,0.10,0.11,0.12), mean=0.0455, stddev=0.0259], bias-{mean,stddev}=-5.837e-05,0.00168, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf10.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, count=4.45e+04, self-repaired-proportion=0, value-avg=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.03,-0.01,-0.003,0.008 0.02,0.03,0.05,0.07,0.08 0.09,0.11,0.12,0.14), mean=0.0493, stddev=0.0258], deriv-avg=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.17,-0.07,0.005,0.07 0.14,0.22,0.38,0.52,0.59 0.67,0.77,0.84,1.1), mean=0.377, stddev=0.185], oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0.01,0.05,0.06 0.07,0.08,0.09,0.16), mean=0.0221, stddev=0.0262], oderiv-count=54912
component name=tdnnf10.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.66,-0.55,-0.45,-0.30 -0.21,-0.09,0.14,0.39,0.51 0.65,0.79,0.87,1.2), mean=0.152, stddev=0.292], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.18,0.25 0.30,0.38,0.43,0.64), mean=0.0758, stddev=0.113]
component name=tdnnf10.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf10.noop type=NoOpComponent, dim=1024
component name=tdnnf11.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-3,0, linear-params-rms=0.001469, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.06,0.06,0.06,0.06 0.06,0.06,0.07,0.07,0.07 0.07,0.07,0.07,0.07), mean=0.0664, stddev=0.00237], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.009,0.01,0.01,0.01 0.01,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.02), mean=0.0165, stddev=0.00189], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.04,0.04,0.06,0.08,0.09 0.10,0.10,0.10,0.10), mean=0.0634, stddev=0.0199], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf11.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,3, linear-params-rms=0.001613, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.02,0.03,0.03,0.03 0.03,0.03,0.03,0.04), mean=0.0257, stddev=0.00277], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.05,0.05,0.05 0.05,0.06,0.06,0.06), mean=0.0516, stddev=0.00179], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.02,0.02,0.04,0.07,0.08 0.09,0.10,0.11,0.11), mean=0.0444, stddev=0.0262], bias-{mean,stddev}=-9.353e-05,0.001564, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf11.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.10,0.16 0.20,0.23,0.27,0.40), mean=0.0405, stddev=0.0717], oderiv-count=3904
component name=tdnnf11.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.85,-0.51,-0.43,-0.31 -0.20,-0.10,0.12,0.36,0.49 0.61,0.74,0.82,1.1), mean=0.136, stddev=0.28], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.19,0.26 0.31,0.40,0.45,0.54), mean=0.0827, stddev=0.118]
component name=tdnnf11.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf11.noop type=NoOpComponent, dim=1024
component name=tdnnf12.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-3,0, linear-params-rms=0.00144, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.06,0.06,0.06,0.06 0.06,0.06,0.07,0.07,0.07 0.07,0.07,0.07,0.07), mean=0.0651, stddev=0.00214], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.008,0.01,0.01,0.01 0.01,0.01,0.02,0.02,0.02 0.02,0.02,0.02,0.02), mean=0.0162, stddev=0.00184], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.04,0.04,0.06,0.08,0.09 0.09,0.10,0.10,0.10), mean=0.0623, stddev=0.019], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf12.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,3, linear-params-rms=0.001604, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.02,0.03,0.03,0.03 0.03,0.03,0.03,0.04), mean=0.0256, stddev=0.00243], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.05,0.05,0.05 0.05,0.05,0.06,0.06), mean=0.0513, stddev=0.00167], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.02,0.02,0.04,0.07,0.08 0.09,0.10,0.11,0.11), mean=0.0439, stddev=0.0266], bias-{mean,stddev}=-0.0001146,0.001502, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf12.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05
component name=tdnnf12.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.69,-0.54,-0.47,-0.35 -0.27,-0.15,0.08,0.34,0.45 0.57,0.72,0.82,1.1), mean=0.0954, stddev=0.284], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.20,0.26 0.31,0.40,0.47,0.61), mean=0.0885, stddev=0.121]
component name=tdnnf12.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf12.noop type=NoOpComponent, dim=1024
component name=tdnnf13.linear type=TdnnComponent, input-dim=1024, output-dim=128, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, orthonormal-constraint=-1, time-offsets=-3,0, linear-params-rms=0.00145, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.06,0.06,0.06,0.06 0.06,0.06,0.07,0.07,0.07 0.07,0.07,0.07,0.07), mean=0.0656, stddev=0.00189], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.009,0.01,0.01,0.01 0.01,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.02), mean=0.0163, stddev=0.00171], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.04 0.04,0.05,0.06,0.08,0.09 0.09,0.10,0.10,0.10), mean=0.0631, stddev=0.018], has-bias=false, rank-in=20, rank-out=64, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf13.affine type=TdnnComponent, input-dim=128, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, time-offsets=0,3, linear-params-rms=0.001678, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.02,0.03,0.03,0.03 0.03,0.03,0.03,0.03), mean=0.0267, stddev=0.00239], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.05,0.06,0.06 0.06,0.06,0.06,0.06), mean=0.0537, stddev=0.00172], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.02,0.02,0.04,0.07,0.09 0.10,0.11,0.11,0.11), mean=0.0458, stddev=0.028], bias-{mean,stddev}=-7.569e-06,0.00134, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha-in=4, alpha-out=4
component name=tdnnf13.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0.01,0.07,0.08 0.10,0.11,0.12,0.16), mean=0.0313, stddev=0.0364], oderiv-count=22144
component name=tdnnf13.batchnorm type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.94,-0.66,-0.59,-0.48 -0.39,-0.24,0.02,0.28,0.43 0.53,0.71,0.85,1.2), mean=0.0272, stddev=0.319], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.19,0.26 0.32,0.38,0.40,0.57), mean=0.0797, stddev=0.116]
component name=tdnnf13.dropout type=GeneralDropoutComponent, dim=1024, block-dim=1024, dropout-proportion=0.428571, continuous=true
component name=tdnnf13.noop type=NoOpComponent, dim=1024
component name=prefinal-l type=LinearComponent, input-dim=1024, output-dim=256, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, params-rms=0.001626, params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.05,0.05,0.05,0.05 0.06,0.06,0.06,0.06), mean=0.052, stddev=0.00213], params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.02,0.03,0.03,0.03 0.03,0.03,0.03,0.03), mean=0.0259, stddev=0.00189], params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.02,0.02 0.02,0.02,0.04,0.07,0.08 0.09,0.09,0.10,0.10), mean=0.0466, stddev=0.0232], orthonormal-constraint=-1, use-natural-gradient=true, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha=4
component name=prefinal-chain.affine type=NaturalGradientAffineComponent, input-dim=256, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, linear-params-rms=0.001796, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.03,0.03,0.03,0.03,0.03 0.03,0.03,0.03,0.05), mean=0.0286, stddev=0.00281], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.05,0.05,0.05,0.05 0.05,0.06,0.06,0.06,0.06 0.06,0.06,0.06,0.06), mean=0.0574, stddev=0.00213], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.03,0.03,0.05,0.07,0.09 0.10,0.11,0.11,0.12), mean=0.0525, stddev=0.0234], bias-{mean,stddev}=2.383e-05,0.001746, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha=4
component name=prefinal-chain.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.13,0.16 0.20,0.24,0.26,0.56), mean=0.0563, stddev=0.0746], oderiv-count=7872
component name=prefinal-chain.batchnorm1 type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.85,-0.66,-0.52,-0.41 -0.33,-0.23,-0.02,0.21,0.36 0.45,0.55,0.63,0.98), mean=-0.00718, stddev=0.268], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.11,0.17 0.20,0.23,0.25,0.30), mean=0.0427, stddev=0.0727]
component name=prefinal-chain.linear type=LinearComponent, input-dim=1024, output-dim=256, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, params-rms=0.001356, params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.04,0.04,0.04,0.04 0.04,0.04,0.04,0.04,0.05 0.05,0.05,0.05,0.05), mean=0.0433, stddev=0.00193], params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.02,0.02,0.02 0.02,0.02,0.02,0.02,0.02 0.02,0.03,0.03,0.03), mean=0.0216, stddev=0.002], params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.01,0.02,0.04,0.06,0.07 0.07,0.08,0.09,0.09), mean=0.0385, stddev=0.0199], orthonormal-constraint=-1, use-natural-gradient=true, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha=4
component name=prefinal-chain.batchnorm2 type=BatchNormComponent, dim=256, block-dim=256, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-7e-06,-6e-06,-5e-06,-5e-06 -3e-06,-2e-06,-2e-07,2e-06,3e-06 4e-06,5e-06,5e-06,6e-06), mean=-9.58e-08, stddev=2.57e-06], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0.32,1.0,1.2 1.4,1.4,1.5,1.7), mean=0.478, stddev=0.51]
component name=output.affine type=NaturalGradientAffineComponent, input-dim=256, output-dim=2824, learning-rate=6.70674e-05, l2-regularize=0.002, max-change=1.5, linear-params-rms=0.0006096, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(4e-06,0.0002,0.0007,0.002 0.003,0.004,0.008,0.01,0.02 0.02,0.02,0.02,0.03), mean=0.00851, stddev=0.00477], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.03,0.03,0.03,0.03,0.03 0.03,0.03,0.04,0.04), mean=0.0324, stddev=0.00125], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.01,0.02,0.03,0.04,0.05 0.06,0.06,0.07,0.07), mean=0.029, stddev=0.0145], bias-{mean,stddev}=-1.633e-07,0.0005509, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha=4
component name=prefinal-xent.affine type=NaturalGradientAffineComponent, input-dim=256, output-dim=1024, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, linear-params-rms=0.0009661, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.003,0.006,0.007,0.008 0.01,0.01,0.02,0.02,0.02 0.02,0.02,0.02,0.03), mean=0.015, stddev=0.0036], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.03,0.03,0.03,0.03 0.03,0.03,0.03,0.03,0.03 0.03,0.03,0.03,0.03), mean=0.0309, stddev=0.00102], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.01,0.01,0.01,0.01 0.01,0.02,0.03,0.04,0.05 0.05,0.05,0.06,0.06), mean=0.0285, stddev=0.0121], bias-{mean,stddev}=-0.0002432,0.0009617, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha=4
component name=prefinal-xent.relu type=RectifiedLinearComponent, dim=1024, self-repair-scale=1e-05, oderiv-rms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0.02,0.03,0.04 0.04,0.05,0.05,0.07), mean=0.0173, stddev=0.0148], oderiv-count=44544
component name=prefinal-xent.batchnorm1 type=BatchNormComponent, dim=1024, block-dim=1024, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-0.46,-0.28,-0.23,-0.18 -0.14,-0.08,0.02,0.16,0.25 0.31,0.40,0.44,0.84), mean=0.0418, stddev=0.158], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.08,0.11 0.13,0.16,0.17,0.24), mean=0.032, stddev=0.0487]
component name=prefinal-xent.linear type=LinearComponent, input-dim=1024, output-dim=256, learning-rate=6.70674e-05, l2-regularize=0.008, max-change=0.75, params-rms=0.0005383, params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.02,0.02 0.02,0.02,0.02,0.02), mean=0.0172, stddev=0.000794], params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.002,0.003,0.004,0.005 0.006,0.008,0.009,0.01,0.01 0.01,0.01,0.01,0.02), mean=0.00845, stddev=0.00166], params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.002,0.002,0.002,0.002 0.003,0.005,0.01,0.02,0.03 0.03,0.03,0.03,0.04), mean=0.0147, stddev=0.00895], orthonormal-constraint=-1, use-natural-gradient=true, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha=4
component name=prefinal-xent.batchnorm2 type=BatchNormComponent, dim=256, block-dim=256, epsilon=0.001, target-rms=1, count=76.4754, test-mode=false, data-mean=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(-5e-06,-5e-06,-4e-06,-3e-06 -3e-06,-2e-06,-2e-07,1e-06,2e-06 2e-06,3e-06,4e-06,6e-06), mean=-1.95e-07, stddev=1.79e-06], data-stddev=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0,0,0,0 0,0,0,0.37,0.47 0.55,0.62,0.63,0.70), mean=0.155, stddev=0.205]
component name=output-xent.affine type=NaturalGradientAffineComponent, input-dim=256, output-dim=2824, learning-rate=0.000335337, l2-regularize=0.002, learning-rate-factor=5, max-change=1.5, linear-params-rms=0.0005043, linear-params-row-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.0001,0.0002,0.0006,0.002 0.003,0.004,0.007,0.01,0.01 0.01,0.02,0.02,0.03), mean=0.00713, stddev=0.00378], linear-params-col-norms=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.02,0.02,0.02,0.02 0.03,0.03,0.03,0.03,0.03 0.03,0.03,0.03,0.03), mean=0.0268, stddev=0.00117], linear-params-singular-values=[percentiles(0,1,2,5 10,20,50,80,90 95,98,99,100)=(0.002,0.002,0.003,0.003 0.004,0.007,0.02,0.04,0.04 0.05,0.05,0.06,0.07), mean=0.0224, stddev=0.0147], bias-{mean,stddev}=-1.753e-10,0.0005481, rank-in=20, rank-out=80, num-samples-history=2000, update-period=4, alpha=4
component name=output-xent.log-softmax type=LogSoftmaxComponent, dim=2824

LOG (nnet3-show-progress[5.5.1035~1-3dd90]:main():nnet3-show-progress.cc:143) Parameter differences per layer are [ tdnn1.affine:1.70731 tdnnf2.linear:1.11898 tdnnf2.affine:1.12876 tdnnf3.linear:0.958162 tdnnf3.affine:0.979875 tdnnf4.linear:0.867516 tdnnf4.affine:0.911458 tdnnf5.linear:0.64634 tdnnf5.affine:0.702191 tdnnf6.linear:0.884592 tdnnf6.affine:0.962964 tdnnf7.linear:0.846537 tdnnf7.affine:0.923415 tdnnf8.linear:0.810105 tdnnf8.affine:0.8955 tdnnf9.linear:0.795645 tdnnf9.affine:0.867322 tdnnf10.linear:0.773765 tdnnf10.affine:0.83939 tdnnf11.linear:0.75206 tdnnf11.affine:0.827152 tdnnf12.linear:0.73712 tdnnf12.affine:0.822784 tdnnf13.linear:0.742539 tdnnf13.affine:0.860415 prefinal-l:0.832499 prefinal-chain.affine:0.92122 prefinal-chain.linear:0.69411 output.affine:0.51917 prefinal-xent.affine:0.495645 prefinal-xent.linear:0.275626 output-xent.affine:0.429798 ]
LOG (nnet3-show-progress[5.5.1035~1-3dd90]:main():nnet3-show-progress.cc:153) Norms of parameter matrices from <new-nnet-in> are [ tdnn1.affine:8.53883 tdnnf2.linear:5.51078 tdnnf2.affine:5.23239 tdnnf3.linear:4.62645 tdnnf3.affine:4.54232 tdnnf4.linear:4.17082 tdnnf4.affine:4.14817 tdnnf5.linear:2.71415 tdnnf5.affine:2.8908 tdnnf6.linear:4.23305 tdnnf6.affine:4.49988 tdnnf7.linear:4.20112 tdnnf7.affine:4.4508 tdnnf8.linear:4.15323 tdnnf8.affine:4.46101 tdnnf9.linear:4.17291 tdnnf9.affine:4.40098 tdnnf10.linear:4.18745 tdnnf10.affine:4.33424 tdnnf11.linear:4.20173 tdnnf11.affine:4.32698 tdnnf12.linear:4.26437 tdnnf12.affine:4.37593 tdnnf13.linear:4.32619 tdnnf13.affine:4.52898 prefinal-l:5.5073 prefinal-chain.affine:4.82084 prefinal-chain.linear:5.41908 output.affine:16.8224 prefinal-xent.affine:3.50047 prefinal-xent.linear:3.88177 output-xent.affine:29.351 ]
LOG (nnet3-show-progress[5.5.1035~1-3dd90]:main():nnet3-show-progress.cc:157) Relative parameter differences per layer are [ tdnn1.affine:0.199533 tdnnf2.linear:0.202498 tdnnf2.affine:0.214909 tdnnf3.linear:0.206364 tdnnf3.affine:0.214981 tdnnf4.linear:0.207359 tdnnf4.affine:0.219091 tdnnf5.linear:0.236678 tdnnf5.affine:0.241307 tdnnf6.linear:0.208442 tdnnf6.affine:0.213381 tdnnf7.linear:0.201014 tdnnf7.affine:0.206811 tdnnf8.linear:0.194458 tdnnf8.affine:0.20007 tdnnf9.linear:0.189974 tdnnf9.affine:0.196394 tdnnf10.linear:0.184299 tdnnf10.affine:0.193067 tdnnf11.linear:0.178533 tdnnf11.affine:0.190591 tdnnf12.linear:0.172387 tdnnf12.affine:0.187439 tdnnf13.linear:0.171264 tdnnf13.affine:0.189542 prefinal-l:0.150849 prefinal-chain.affine:0.190854 prefinal-chain.linear:0.127825 output.affine:0.0308694 prefinal-xent.affine:0.141325 prefinal-xent.linear:0.0709326 output-xent.affine:0.0146415 ]
LOG (nnet3-show-progress[5.5.1035~1-3dd90]:PrintProfile():cu-device.cc:563) -----
[cudevice profile]
Total GPU time:	0s (may involve some double-counting)
-----
# Accounting: time=20 threads=1
# Ended (code 0) at Wed Jul 20 11:25:10 EDT 2022, elapsed time 20 seconds

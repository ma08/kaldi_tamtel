# nnet3-chain-train --use-gpu=yes --apply-deriv-weights=False --l2-regularize=0.0 --leaky-hmm-coefficient=0.1 --read-cache=exp/chain_cleaned_1d/tdnn1d_sp/cache.6 --write-cache=exp/chain_cleaned_1d/tdnn1d_sp/cache.7 --xent-regularize=0.1 --print-interval=10 --momentum=0.0 --max-param-change=2.0 --backstitch-training-scale=0.0 --backstitch-training-interval=1 --l2-regularize-factor=0.25 --optimization.memory-compression-level=2 --srand=6 "nnet3-am-copy --raw=true --learning-rate=0.0009466522603081897 --scale=1.0 exp/chain_cleaned_1d/tdnn1d_sp/6.mdl - |nnet3-copy --edits='set-dropout-proportion name=* proportion=0.0' - - |" exp/chain_cleaned_1d/tdnn1d_sp/den.fst "ark,bg:nnet3-chain-copy-egs                          --frame-shift=1                         ark:exp/chain_cleaned_1d/tdnn1d_sp/egs/cegs.19.ark ark:- |                         nnet3-chain-shuffle-egs --buffer-size=5000                         --srand=6 ark:- ark:- | nnet3-chain-merge-egs                         --minibatch-size=64 ark:- ark:- |" exp/chain_cleaned_1d/tdnn1d_sp/7.1.raw 
# Started at Sun May 29 16:06:46 UTC 2022
#
nnet3-chain-train --use-gpu=yes --apply-deriv-weights=False --l2-regularize=0.0 --leaky-hmm-coefficient=0.1 --read-cache=exp/chain_cleaned_1d/tdnn1d_sp/cache.6 --write-cache=exp/chain_cleaned_1d/tdnn1d_sp/cache.7 --xent-regularize=0.1 --print-interval=10 --momentum=0.0 --max-param-change=2.0 --backstitch-training-scale=0.0 --backstitch-training-interval=1 --l2-regularize-factor=0.25 --optimization.memory-compression-level=2 --srand=6 "nnet3-am-copy --raw=true --learning-rate=0.0009466522603081897 --scale=1.0 exp/chain_cleaned_1d/tdnn1d_sp/6.mdl - |nnet3-copy --edits='set-dropout-proportion name=* proportion=0.0' - - |" exp/chain_cleaned_1d/tdnn1d_sp/den.fst 'ark,bg:nnet3-chain-copy-egs                          --frame-shift=1                         ark:exp/chain_cleaned_1d/tdnn1d_sp/egs/cegs.19.ark ark:- |                         nnet3-chain-shuffle-egs --buffer-size=5000                         --srand=6 ark:- ark:- | nnet3-chain-merge-egs                         --minibatch-size=64 ark:- ark:- |' exp/chain_cleaned_1d/tdnn1d_sp/7.1.raw 
WARNING (nnet3-chain-train[5.5.1009~1-e4940]:SelectGpuId():cu-device.cc:243) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet3-chain-train[5.5.1009~1-e4940]:SelectGpuIdAuto():cu-device.cc:438) Selecting from 1 GPUs
LOG (nnet3-chain-train[5.5.1009~1-e4940]:SelectGpuIdAuto():cu-device.cc:453) cudaSetDevice(0): Tesla K80	free:11210M, used:230M, total:11441M, free/total:0.979854
LOG (nnet3-chain-train[5.5.1009~1-e4940]:SelectGpuIdAuto():cu-device.cc:501) Device: 0, mem_ratio: 0.979854
LOG (nnet3-chain-train[5.5.1009~1-e4940]:SelectGpuId():cu-device.cc:382) Trying to select device: 0
LOG (nnet3-chain-train[5.5.1009~1-e4940]:SelectGpuIdAuto():cu-device.cc:511) Success selecting device 0 free mem ratio: 0.979854
LOG (nnet3-chain-train[5.5.1009~1-e4940]:FinalizeActiveGpu():cu-device.cc:338) The active GPU is [0]: Tesla K80	free:10938M, used:503M, total:11441M, free/total:0.956036 version 3.7
nnet3-copy '--edits=set-dropout-proportion name=* proportion=0.0' - - 
nnet3-am-copy --raw=true --learning-rate=0.0009466522603081897 --scale=1.0 exp/chain_cleaned_1d/tdnn1d_sp/6.mdl - 
LOG (nnet3-am-copy[5.5.1009~1-e4940]:main():nnet3-am-copy.cc:153) Copied neural net from exp/chain_cleaned_1d/tdnn1d_sp/6.mdl to raw format as -
LOG (nnet3-copy[5.5.1009~1-e4940]:ReadEditConfig():nnet-utils.cc:1413) Set dropout proportions for 13 components.
LOG (nnet3-copy[5.5.1009~1-e4940]:main():nnet3-copy.cc:123) Copied raw neural net from - to -
LOG (nnet3-chain-train[5.5.1009~1-e4940]:NnetChainTrainer():nnet-chain-training.cc:51) Read computation cache from exp/chain_cleaned_1d/tdnn1d_sp/cache.6
nnet3-chain-merge-egs --minibatch-size=64 ark:- ark:- 
nnet3-chain-shuffle-egs --buffer-size=5000 --srand=6 ark:- ark:- 
nnet3-chain-copy-egs --frame-shift=1 ark:exp/chain_cleaned_1d/tdnn1d_sp/egs/cegs.19.ark ark:- 
LOG (nnet3-chain-train[5.5.1009~1-e4940]:AllocateNewRegion():cu-allocator.cc:478) About to allocate new memory region of 62914560 bytes; current memory info is: free:118M, used:11323M, total:11441M, free/total:0.0103354
LOG (nnet3-chain-train[5.5.1009~1-e4940]:AllocateNewRegion():cu-allocator.cc:478) About to allocate new memory region of 31457280 bytes; current memory info is: free:58M, used:11383M, total:11441M, free/total:0.00509123
LOG (nnet3-chain-train[5.5.1009~1-e4940]:AllocateNewRegion():cu-allocator.cc:478) About to allocate new memory region of 41943040 bytes; current memory info is: free:28M, used:11413M, total:11441M, free/total:0.00246914
LOG (nnet3-chain-train[5.5.1009~1-e4940]:PrintMemoryUsage():cu-allocator.cc:340) Memory usage: 755800576/811597824 bytes currently allocated/total-held; 537/15 blocks currently allocated/free; largest free/allocated block sizes are 52953088/14680064; time taken total/cudaMalloc is 0.012825/0.0315509, synchronized the GPU 0 times out of 99 frees; device memory info: free:28M, used:11413M, total:11441M, free/total:0.00246914maximum allocated: 773207552current allocated: 755800576
ERROR (nnet3-chain-train[5.5.1009~1-e4940]:AllocateNewRegion():cu-allocator.cc:491) Failed to allocate a memory region of 41943040 bytes.  Possibly this is due to sharing the GPU.  Try switching the GPUs to exclusive mode (nvidia-smi -c 3) and using the option --use-gpu=wait to scripts like steps/nnet3/chain/train.py.  Memory info: free:28M, used:11413M, total:11441M, free/total:0.00246914 CUDA error: 'out of memory'

[ Stack-Trace: ]
nnet3-chain-train(kaldi::MessageLogger::LogMessage() const+0xb61) [0x55ff16bcfc67]
nnet3-chain-train(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&)+0x21) [0x55ff1686858d]
nnet3-chain-train(kaldi::CuMemoryAllocator::AllocateNewRegion(unsigned long)+0x471) [0x55ff16aea979]
nnet3-chain-train(kaldi::CuMemoryAllocator::MallocPitch(unsigned long, unsigned long, unsigned long*)+0x499) [0x55ff16aeb239]
nnet3-chain-train(kaldi::CuMatrix<float>::Resize(int, int, kaldi::MatrixResizeType, kaldi::MatrixStrideType)+0x191) [0x55ff16aab665]
nnet3-chain-train(kaldi::nnet3::NnetComputer::ExecuteCommand()+0xa6) [0x55ff16937822]
nnet3-chain-train(kaldi::nnet3::NnetComputer::Run()+0x178) [0x55ff16938f94]
nnet3-chain-train(kaldi::nnet3::NnetChainTrainer::TrainInternal(kaldi::nnet3::NnetChainExample const&, kaldi::nnet3::NnetComputation const&)+0x5b) [0x55ff168b9107]
nnet3-chain-train(kaldi::nnet3::NnetChainTrainer::Train(kaldi::nnet3::NnetChainExample const&)+0xe4) [0x55ff168b94b0]
nnet3-chain-train(main+0x75f) [0x55ff1686749f]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xe7) [0x7f3cdb8dac87]
nnet3-chain-train(_start+0x2a) [0x55ff16866c3a]

WARNING (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:464) Printing some background info since error was detected
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:465) matrix m1(64, 100), m2(13312, 40), m3(12928, 220), m4(12928, 220), m5(12928, 1024), m6(12928, 1024), m7(12928, 1024), m8(12928, 1024), m9(12928, 1024), m10(12928, 1024), m11(12864, 128), m12(12864, 128), m13(12800, 1024), m14(12800, 1024), m15(12800, 1024), m16(12800, 1024), m17(12800, 1024), m18(12800, 1024), m19(12800, 1024), m20(12736, 128), m21(12736, 128), m22(12672, 1024), m23(12672, 1024), m24(12672, 1024), m25(12672, 1024), m26(12672, 1024), m27(12672, 1024), m28(12672, 1024), m29(12608, 128), m30(12608, 128), m31(12672, 128), m32(12672, 128), m33(4224, 1024), m34(4224, 1024), m35(4224, 1024), m36(4224, 1024), m37(4224, 1024), m38(4224, 1024), m39(4224, 1024), m40(4224, 128), m41(4224, 128), m42(4224, 1024), m43(4224, 1024), m44(4224, 1024), m45(4224, 1024), m46(4224, 1024), m47(4224, 1024), m48(4224, 1024), m49(4160, 128), m50(4160, 128), m51(4096, 1024), m52(4096, 1024), m53(4096, 1024), m54(4096, 1024), m55(4096, 1024), m56(4096, 1024), m57(4096, 1024), m58(4032, 128), m59(4032, 128), m60(3968, 1024), m61(3968, 1024), m62(3968, 1024), m63(3968, 1024), m64(3968, 1024), m65(3968, 1024), m66(3968, 1024), m67(3904, 128), m68(3904, 128), m69(3840, 1024), m70(3840, 1024), m71(3840, 1024), m72(3840, 1024), m73(3840, 1024), m74(3840, 1024), m75(3840, 1024), m76(3776, 128), m77(3776, 128), m78(3712, 1024), m79(3712, 1024), m80(3712, 1024), m81(3712, 1024), m82(3712, 1024), m83(3712, 1024), m84(3712, 1024), m85(3648, 128), m86(3648, 128), m87(3584, 1024), m88(3584, 1024), m89(3584, 1024), m90(3584, 1024), m91(3584, 1024), m92(3584, 1024), m93(3584, 1024), m94(3520, 128), m95(3520, 128), m96(3456, 1024), m97(3456, 1024), m98(3456, 1024), m99(3456, 1024), m100(3456, 1024), m101(3456, 1024), m102(3456, 1024), m103(3392, 128), m104(3392, 128), m105(3328, 1024), m106(3328, 1024), m107(3328, 1024), m108(3328, 1024), m109(3328, 1024), m110(3328, 1024), m111(3328, 1024), m112(3264, 128), m113(3264, 128), m114(3200, 1024), m115(3200, 1024), m116(3200, 1024), m117(3200, 1024), m118(3200, 1024), m119(3200, 1024), m120(3200, 256), m121(3200, 256), m122(3200, 1024), m123(3200, 1024), m124(3200, 1024), m125(3200, 1024), m126(3200, 256), m127(3200, 256), m128(3200, 3177), m129(3200, 3177), m130(3200, 3177), m131(3200, 3177), m132(3200, 256), m133(3200, 1024), m134(3200, 1024), m135(3200, 1024), m136(3200, 1024), m137(3200, 256), m138(3200, 256), m139(3200, 3177), m140(3200, 3177)
# The following show how matrices correspond to network-nodes and
# cindex-ids.  Format is: matrix = <node-id>.[value|deriv][ <list-of-cindex-ids> ]
# where a cindex-id is written as (n,t[,x]) but ranges of t values are compressed
# so we write (n, tfirst:tlast).
m1 == value: ivector[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ... ,0), (52,0), (53,0), (54,0), (55,0), (56,0), (57,0), (58,0), (59,0), (60,0), (61,0), (62,0), (63,0)]
m2 == value: input[(0,-28:179), (1,-28:179), (2,-28:179), (3,-28:179), (4,-28:179), (5,-28:179), (6,-28:179), (7,-28:1 ... ), (57,-28:179), (58,-28:179), (59,-28:179), (60,-28:179), (61,-28:179), (62,-28:179), (63,-28:179)]
m3 == value: lda_input[(0,-27), (1,-27), (2,-27), (3,-27), (4,-27), (5,-27), (6,-27), (7,-27), (8,-27), (9,-27), (10,-27), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m4 == value: lda[(0,-27), (1,-27), (2,-27), (3,-27), (4,-27), (5,-27), (6,-27), (7,-27), (8,-27), (9,-27), (10,-27), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m5 == value: tdnn1.affine[(0,-27), (1,-27), (2,-27), (3,-27), (4,-27), (5,-27), (6,-27), (7,-27), (8,-27), (9,-27), (10,-27), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m6 == deriv: tdnn1.relu_input[(0,-27), (1,-27), (2,-27), (3,-27), (4,-27), (5,-27), (6,-27), (7,-27), (8,-27), (9,-27), (10,-27), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m7 == value: tdnn1.batchnorm[(0,-27), (1,-27), (2,-27), (3,-27), (4,-27), (5,-27), (6,-27), (7,-27), (8,-27), (9,-27), (10,-27), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m8 == value: tdnn1.dropout[(0,-27), (1,-27), (2,-27), (3,-27), (4,-27), (5,-27), (6,-27), (7,-27), (8,-27), (9,-27), (10,-27), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m9 == deriv: tdnn1.dropout[(0,-27), (1,-27), (2,-27), (3,-27), (4,-27), (5,-27), (6,-27), (7,-27), (8,-27), (9,-27), (10,-27), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m10 == deriv: tdnnf2.linear_input[(0,-27), (1,-27), (2,-27), (3,-27), (4,-27), (5,-27), (6,-27), (7,-27), (8,-27), (9,-27), (10,-27), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m11 == value: tdnnf2.linear[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m12 == deriv: tdnnf2.affine_input[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,174), (55,174), (56,174), (57,174), (58,174), (59,174), (60,174), (61,174), (62,174), (63,174)]
m13 == value: tdnnf2.affine[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m14 == deriv: tdnnf2.relu_input[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m15 == value: tdnnf2.batchnorm[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m16 == value: tdnnf2.dropout[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m17 == value: tdnnf2.noop_input[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m18 == deriv: tdnnf2.noop[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m19 == deriv: tdnnf3.linear_input[(0,-26), (1,-26), (2,-26), (3,-26), (4,-26), (5,-26), (6,-26), (7,-26), (8,-26), (9,-26), (10,-26), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m20 == value: tdnnf3.linear[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m21 == deriv: tdnnf3.affine_input[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,173), (55,173), (56,173), (57,173), (58,173), (59,173), (60,173), (61,173), (62,173), (63,173)]
m22 == value: tdnnf3.affine[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m23 == deriv: tdnnf3.relu_input[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m24 == value: tdnnf3.batchnorm[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m25 == value: tdnnf3.dropout[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m26 == value: tdnnf3.noop_input[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m27 == deriv: tdnnf3.noop[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m28 == deriv: tdnnf4.linear_input[(0,-25), (1,-25), (2,-25), (3,-25), (4,-25), (5,-25), (6,-25), (7,-25), (8,-25), (9,-25), (10,-25), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m29 == value: tdnnf4.linear[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m30 == deriv: tdnnf4.linear[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,172), (55,172), (56,172), (57,172), (58,172), (59,172), (60,172), (61,172), (62,172), (63,172)]
m31 == value: tdnnf4.affine_input[(0,-24:-23), (0,-2147483648), (1,-24:-23), (1,-2147483648), (2,-24:-23), (2,-2147483648), (3,-24:-2 ... 48), (61,171:172), (61,-2147483648), (62,171:172), (62,-2147483648), (63,171:172), (63,-2147483648)]
m32 == deriv: tdnnf4.affine_input[(0,-24:-23), (0,-2147483648), (1,-24:-23), (1,-2147483648), (2,-24:-23), (2,-2147483648), (3,-24:-2 ... 48), (61,171:172), (61,-2147483648), (62,171:172), (62,-2147483648), (63,171:172), (63,-2147483648)]
m33 == value: tdnnf4.affine[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m34 == deriv: tdnnf4.relu_input[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m35 == value: tdnnf4.batchnorm[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m36 == value: tdnnf4.dropout[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m37 == value: tdnnf4.noop_input[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m38 == deriv: tdnnf4.noop[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m39 == deriv: tdnnf5.linear_input[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m40 == value: tdnnf5.linear[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m41 == deriv: tdnnf5.affine_input[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m42 == value: tdnnf5.affine[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m43 == deriv: tdnnf5.relu_input[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m44 == value: tdnnf5.batchnorm[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m45 == value: tdnnf5.dropout[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m46 == value: tdnnf5.noop_input[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m47 == deriv: tdnnf5.noop[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m48 == deriv: tdnnf6.linear_input[(0,-24), (1,-24), (2,-24), (3,-24), (4,-24), (5,-24), (6,-24), (7,-24), (8,-24), (9,-24), (10,-24), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m49 == value: tdnnf6.linear[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m50 == deriv: tdnnf6.affine_input[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,171), (55,171), (56,171), (57,171), (58,171), (59,171), (60,171), (61,171), (62,171), (63,171)]
m51 == value: tdnnf6.affine[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m52 == deriv: tdnnf6.relu_input[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m53 == value: tdnnf6.batchnorm[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m54 == value: tdnnf6.dropout[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m55 == value: tdnnf6.noop_input[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m56 == deriv: tdnnf6.noop[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m57 == deriv: tdnnf7.linear_input[(0,-21), (1,-21), (2,-21), (3,-21), (4,-21), (5,-21), (6,-21), (7,-21), (8,-21), (9,-21), (10,-21), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m58 == value: tdnnf7.linear[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m59 == deriv: tdnnf7.affine_input[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,168), (55,168), (56,168), (57,168), (58,168), (59,168), (60,168), (61,168), (62,168), (63,168)]
m60 == value: tdnnf7.affine[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m61 == deriv: tdnnf7.relu_input[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m62 == value: tdnnf7.batchnorm[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m63 == value: tdnnf7.dropout[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m64 == value: tdnnf7.noop_input[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m65 == deriv: tdnnf7.noop[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m66 == deriv: tdnnf8.linear_input[(0,-18), (1,-18), (2,-18), (3,-18), (4,-18), (5,-18), (6,-18), (7,-18), (8,-18), (9,-18), (10,-18), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m67 == value: tdnnf8.linear[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m68 == deriv: tdnnf8.affine_input[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,165), (55,165), (56,165), (57,165), (58,165), (59,165), (60,165), (61,165), (62,165), (63,165)]
m69 == value: tdnnf8.affine[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m70 == deriv: tdnnf8.relu_input[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m71 == value: tdnnf8.batchnorm[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m72 == value: tdnnf8.dropout[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m73 == value: tdnnf8.noop_input[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m74 == deriv: tdnnf8.noop[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m75 == deriv: tdnnf9.linear_input[(0,-15), (1,-15), (2,-15), (3,-15), (4,-15), (5,-15), (6,-15), (7,-15), (8,-15), (9,-15), (10,-15), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m76 == value: tdnnf9.linear[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m77 == deriv: tdnnf9.affine_input[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,162), (55,162), (56,162), (57,162), (58,162), (59,162), (60,162), (61,162), (62,162), (63,162)]
m78 == value: tdnnf9.affine[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m79 == deriv: tdnnf9.relu_input[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m80 == value: tdnnf9.batchnorm[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m81 == value: tdnnf9.dropout[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m82 == value: tdnnf9.noop_input[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m83 == deriv: tdnnf9.noop[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m84 == deriv: tdnnf10.linear_input[(0,-12), (1,-12), (2,-12), (3,-12), (4,-12), (5,-12), (6,-12), (7,-12), (8,-12), (9,-12), (10,-12), ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m85 == value: tdnnf10.linear[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m86 == deriv: tdnnf10.affine_input[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,159), (55,159), (56,159), (57,159), (58,159), (59,159), (60,159), (61,159), (62,159), (63,159)]
m87 == value: tdnnf10.affine[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m88 == deriv: tdnnf10.relu_input[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m89 == value: tdnnf10.batchnorm[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m90 == value: tdnnf10.dropout[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m91 == value: tdnnf10.noop_input[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m92 == deriv: tdnnf10.noop[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m93 == deriv: tdnnf11.linear_input[(0,-9), (1,-9), (2,-9), (3,-9), (4,-9), (5,-9), (6,-9), (7,-9), (8,-9), (9,-9), (10,-9), (11,-9), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m94 == value: tdnnf11.linear[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m95 == deriv: tdnnf11.affine_input[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,156), (55,156), (56,156), (57,156), (58,156), (59,156), (60,156), (61,156), (62,156), (63,156)]
m96 == value: tdnnf11.affine[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m97 == deriv: tdnnf11.relu_input[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m98 == value: tdnnf11.batchnorm[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m99 == value: tdnnf11.dropout[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m100 == value: tdnnf11.noop_input[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m101 == deriv: tdnnf11.noop[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m102 == deriv: tdnnf12.linear_input[(0,-6), (1,-6), (2,-6), (3,-6), (4,-6), (5,-6), (6,-6), (7,-6), (8,-6), (9,-6), (10,-6), (11,-6), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m103 == value: tdnnf12.linear[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m104 == deriv: tdnnf12.affine_input[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,153), (55,153), (56,153), (57,153), (58,153), (59,153), (60,153), (61,153), (62,153), (63,153)]
m105 == value: tdnnf12.affine[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m106 == deriv: tdnnf12.relu_input[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m107 == value: tdnnf12.batchnorm[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m108 == value: tdnnf12.dropout[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m109 == value: tdnnf12.noop_input[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m110 == deriv: tdnnf12.noop[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m111 == deriv: tdnnf13.linear_input[(0,-3), (1,-3), (2,-3), (3,-3), (4,-3), (5,-3), (6,-3), (7,-3), (8,-3), (9,-3), (10,-3), (11,-3), ( ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m112 == value: tdnnf13.linear[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m113 == deriv: tdnnf13.affine_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,150), (55,150), (56,150), (57,150), (58,150), (59,150), (60,150), (61,150), (62,150), (63,150)]
m114 == value: tdnnf13.affine[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m115 == deriv: tdnnf13.relu_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m116 == value: tdnnf13.batchnorm[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m117 == value: tdnnf13.dropout[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m118 == value: tdnnf13.noop_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m119 == deriv: prefinal-l_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m120 == value: prefinal-l[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m121 == deriv: prefinal-xent.affine_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m122 == value: prefinal-xent.affine[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m123 == deriv: prefinal-xent.relu_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m124 == value: prefinal-xent.batchnorm1[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m125 == deriv: prefinal-xent.linear_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m126 == value: prefinal-xent.linear[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m127 == deriv: output-xent.affine_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m128 == value: output-xent.affine[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m129 == deriv: output-xent.log-softmax_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m130 == value: output-xent.log-softmax[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m131 == deriv: output-xent[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m132 == deriv: prefinal-chain.affine_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m133 == value: prefinal-chain.affine[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m134 == deriv: prefinal-chain.relu_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m135 == value: prefinal-chain.batchnorm1[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m136 == deriv: prefinal-chain.linear_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m137 == value: prefinal-chain.linear[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m138 == deriv: output.affine_input[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m139 == value: output.affine[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]
m140 == deriv: output[(0,0), (1,0), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0 ...  (54,147), (55,147), (56,147), (57,147), (58,147), (59,147), (60,147), (61,147), (62,147), (63,147)]

LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c0: m1 = user input [for node: 'ivector']
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c1: m2 = user input [for node: 'input']
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c2: [no-op-permanent]
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c3: m3 = undefined(12928,220)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c4: m3(0:12927, 0:39).CopyRows(1, m2[0, 208, 416, 624, 832, 1040, 1248, 1456, 1664, 1872, 2080, 2288 ...  10601, 10809, 11017, 11225, 11433, 11641, 11849, 12057, 12265, 12473, 12681, 12889, 13097, 13305])
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c5: m3(0:12927, 40:79).CopyRows(1, m2[1, 209, 417, 625, 833, 1041, 1249, 1457, 1665, 1873, 2081, 228 ...  10602, 10810, 11018, 11226, 11434, 11642, 11850, 12058, 12266, 12474, 12682, 12890, 13098, 13306])
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c6: m3(0:12927, 80:119).CopyRows(1, m2[2, 210, 418, 626, 834, 1042, 1250, 1458, 1666, 1874, 2082, 22 ...  10603, 10811, 11019, 11227, 11435, 11643, 11851, 12059, 12267, 12475, 12683, 12891, 13099, 13307])
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c7: m2 = []
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c8: m3(0:12927, 120:219).CopyRows(1, m1[0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63,  ... 3, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63, 0:63])
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c9: m1 = []
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c10: m4 = undefined(12928,220)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c11: lda.Propagate(NULL, m3, &m4)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c12: m3 = []
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c13: m5 = undefined(12928,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c14: tdnn1.affine.Propagate(NULL, m4, &m5)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c15: CompressMatrix(m4, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c16: tdnn1.relu.Propagate(NULL, m5, &m5)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c17: m7 = undefined(12928,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c18: tdnn1.batchnorm.Propagate(NULL, m5, &m7)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c19: CompressMatrix(m5, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c20: m8 = undefined(12928,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c21: tdnn1.dropout.Propagate(precomputed_indexes[1], m7, &m8)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c22: CompressMatrix(m7, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c23: m11 = undefined(12864,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c24: m11.set(0) [dim = 12864 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c25: tdnnf2.linear.Propagate(precomputed_indexes[2], m8, &m11)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c26: m13 = undefined(12800,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c27: tdnnf2.affine.Propagate(precomputed_indexes[3], m11, &m13)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c28: CompressMatrix(m11, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c29: tdnnf2.relu.Propagate(NULL, m13, &m13)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c30: m15 = undefined(12800,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c31: tdnnf2.batchnorm.Propagate(NULL, m13, &m15)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c32: CompressMatrix(m13, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c33: m16 = undefined(12800,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c34: tdnnf2.dropout.Propagate(precomputed_indexes[4], m15, &m16)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c35: CompressMatrix(m15, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c36: m17 = undefined(12800,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c37: m17 = 0.66 * m8(64:12863, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c38: CompressMatrix(m8, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c39: m17 += m16
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c40: tdnnf2.noop.Propagate(NULL, m17, &m17)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c41: m20 = undefined(12736,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c42: m20.set(0) [dim = 12736 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c43: tdnnf3.linear.Propagate(precomputed_indexes[5], m17, &m20)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c44: m22 = undefined(12672,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c45: tdnnf3.affine.Propagate(precomputed_indexes[6], m20, &m22)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c46: CompressMatrix(m20, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c47: tdnnf3.relu.Propagate(NULL, m22, &m22)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c48: m24 = undefined(12672,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c49: tdnnf3.batchnorm.Propagate(NULL, m22, &m24)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c50: CompressMatrix(m22, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c51: m25 = undefined(12672,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c52: tdnnf3.dropout.Propagate(precomputed_indexes[7], m24, &m25)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c53: CompressMatrix(m24, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c54: m26 = undefined(12672,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c55: m26 = 0.66 * m17(64:12735, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c56: CompressMatrix(m17, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c57: m26 += m25
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c58: tdnnf3.noop.Propagate(NULL, m26, &m26)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c59: m29 = undefined(12608,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c60: m29.set(0) [dim = 12608 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c61: tdnnf4.linear.Propagate(precomputed_indexes[8], m26, &m29)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c62: m31 = undefined(12672,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c63: m31.set(0) [dim = 12672 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c64: m31.CopyRows(1, m29[0, 64, -1, 1, 65, -1, 2, 66, -1, 3, 67, -1, 4, 68, -1, 5, 69, -1, 6, 70, -1 ... 602, -1, 12539, 12603, -1, 12540, 12604, -1, 12541, 12605, -1, 12542, 12606, -1, 12543, 12607, -1])
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c65: m33 = undefined(4224,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c66: tdnnf4.affine.Propagate(precomputed_indexes[9], m31, &m33)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c67: CompressMatrix(m31, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c68: tdnnf4.relu.Propagate(NULL, m33, &m33)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c69: m35 = undefined(4224,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c70: tdnnf4.batchnorm.Propagate(NULL, m33, &m35)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c71: CompressMatrix(m33, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c72: m36 = undefined(4224,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c73: tdnnf4.dropout.Propagate(precomputed_indexes[10], m35, &m36)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c74: CompressMatrix(m35, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c75: m37 = undefined(4224,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c76: m37.CopyRows(0.66, m26[64:127, 256:319, 448:511, 640:703, 832:895, 1024:1087, 1216:1279, 1408:1 ... :11263, 11392:11455, 11584:11647, 11776:11839, 11968:12031, 12160:12223, 12352:12415, 12544:12607])
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c77: CompressMatrix(m26, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c78: m37 += m36
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c79: tdnnf4.noop.Propagate(NULL, m37, &m37)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c80: m40 = undefined(4224,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c81: m40.set(0) [dim = 4224 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c82: tdnnf5.linear.Propagate(precomputed_indexes[11], m37, &m40)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c83: m42.swap(m36) [dim = 4224 x 1024]
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c84: tdnnf5.affine.Propagate(precomputed_indexes[12], m40, &m42)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c85: CompressMatrix(m40, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c86: tdnnf5.relu.Propagate(NULL, m42, &m42)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c87: m44 = undefined(4224,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c88: tdnnf5.batchnorm.Propagate(NULL, m42, &m44)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c89: CompressMatrix(m42, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c90: m45 = undefined(4224,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c91: tdnnf5.dropout.Propagate(precomputed_indexes[13], m44, &m45)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c92: CompressMatrix(m44, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c93: m46 = undefined(4224,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c94: m46 = 0.66 * m37
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c95: CompressMatrix(m37, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c96: m46 += m45
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c97: tdnnf5.noop.Propagate(NULL, m46, &m46)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c98: m49 = undefined(4160,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c99: m49.set(0) [dim = 4160 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c100: tdnnf6.linear.Propagate(precomputed_indexes[14], m46, &m49)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c101: m51 = undefined(4096,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c102: tdnnf6.affine.Propagate(precomputed_indexes[15], m49, &m51)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c103: CompressMatrix(m49, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c104: tdnnf6.relu.Propagate(NULL, m51, &m51)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c105: m53 = undefined(4096,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c106: tdnnf6.batchnorm.Propagate(NULL, m51, &m53)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c107: CompressMatrix(m51, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c108: m54 = undefined(4096,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c109: tdnnf6.dropout.Propagate(precomputed_indexes[16], m53, &m54)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c110: CompressMatrix(m53, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c111: m55 = undefined(4096,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c112: m55 = 0.66 * m46(64:4159, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c113: CompressMatrix(m46, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c114: m55 += m54
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c115: tdnnf6.noop.Propagate(NULL, m55, &m55)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c116: m58 = undefined(4032,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c117: m58.set(0) [dim = 4032 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c118: tdnnf7.linear.Propagate(precomputed_indexes[17], m55, &m58)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c119: m60 = undefined(3968,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c120: tdnnf7.affine.Propagate(precomputed_indexes[18], m58, &m60)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c121: CompressMatrix(m58, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c122: tdnnf7.relu.Propagate(NULL, m60, &m60)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c123: m62 = undefined(3968,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c124: tdnnf7.batchnorm.Propagate(NULL, m60, &m62)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c125: CompressMatrix(m60, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c126: m63 = undefined(3968,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c127: tdnnf7.dropout.Propagate(precomputed_indexes[19], m62, &m63)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c128: CompressMatrix(m62, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c129: m64 = undefined(3968,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c130: m64 = 0.66 * m55(64:4031, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c131: CompressMatrix(m55, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c132: m64 += m63
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c133: tdnnf7.noop.Propagate(NULL, m64, &m64)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c134: m67 = undefined(3904,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c135: m67.set(0) [dim = 3904 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c136: tdnnf8.linear.Propagate(precomputed_indexes[20], m64, &m67)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c137: m69 = undefined(3840,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c138: tdnnf8.affine.Propagate(precomputed_indexes[21], m67, &m69)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c139: CompressMatrix(m67, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c140: tdnnf8.relu.Propagate(NULL, m69, &m69)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c141: m71 = undefined(3840,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c142: tdnnf8.batchnorm.Propagate(NULL, m69, &m71)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c143: CompressMatrix(m69, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c144: m72 = undefined(3840,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c145: tdnnf8.dropout.Propagate(precomputed_indexes[22], m71, &m72)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c146: CompressMatrix(m71, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c147: m73 = undefined(3840,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c148: m73 = 0.66 * m64(64:3903, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c149: CompressMatrix(m64, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c150: m73 += m72
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c151: tdnnf8.noop.Propagate(NULL, m73, &m73)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c152: m76 = undefined(3776,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c153: m76.set(0) [dim = 3776 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c154: tdnnf9.linear.Propagate(precomputed_indexes[23], m73, &m76)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c155: m78 = undefined(3712,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c156: tdnnf9.affine.Propagate(precomputed_indexes[24], m76, &m78)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c157: CompressMatrix(m76, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c158: tdnnf9.relu.Propagate(NULL, m78, &m78)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c159: m80 = undefined(3712,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c160: tdnnf9.batchnorm.Propagate(NULL, m78, &m80)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c161: CompressMatrix(m78, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c162: m81 = undefined(3712,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c163: tdnnf9.dropout.Propagate(precomputed_indexes[25], m80, &m81)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c164: CompressMatrix(m80, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c165: m82 = undefined(3712,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c166: m82 = 0.66 * m73(64:3775, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c167: CompressMatrix(m73, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c168: m82 += m81
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c169: tdnnf9.noop.Propagate(NULL, m82, &m82)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c170: m85 = undefined(3648,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c171: m85.set(0) [dim = 3648 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c172: tdnnf10.linear.Propagate(precomputed_indexes[26], m82, &m85)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c173: m87 = undefined(3584,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c174: tdnnf10.affine.Propagate(precomputed_indexes[27], m85, &m87)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c175: CompressMatrix(m85, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c176: tdnnf10.relu.Propagate(NULL, m87, &m87)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c177: m89 = undefined(3584,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c178: tdnnf10.batchnorm.Propagate(NULL, m87, &m89)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c179: CompressMatrix(m87, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c180: m90 = undefined(3584,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c181: tdnnf10.dropout.Propagate(precomputed_indexes[28], m89, &m90)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c182: CompressMatrix(m89, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c183: m91 = undefined(3584,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c184: m91 = 0.66 * m82(64:3647, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c185: CompressMatrix(m82, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c186: m91 += m90
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c187: tdnnf10.noop.Propagate(NULL, m91, &m91)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c188: m94 = undefined(3520,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c189: m94.set(0) [dim = 3520 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c190: tdnnf11.linear.Propagate(precomputed_indexes[29], m91, &m94)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c191: m96 = undefined(3456,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c192: tdnnf11.affine.Propagate(precomputed_indexes[30], m94, &m96)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c193: CompressMatrix(m94, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c194: tdnnf11.relu.Propagate(NULL, m96, &m96)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c195: m98 = undefined(3456,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c196: tdnnf11.batchnorm.Propagate(NULL, m96, &m98)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c197: CompressMatrix(m96, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c198: m99 = undefined(3456,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c199: tdnnf11.dropout.Propagate(precomputed_indexes[31], m98, &m99)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c200: CompressMatrix(m98, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c201: m100 = undefined(3456,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c202: m100 = 0.66 * m91(64:3519, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c203: CompressMatrix(m91, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c204: m100 += m99
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c205: tdnnf11.noop.Propagate(NULL, m100, &m100)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c206: m103 = undefined(3392,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c207: m103.set(0) [dim = 3392 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c208: tdnnf12.linear.Propagate(precomputed_indexes[32], m100, &m103)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c209: m105 = undefined(3328,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c210: tdnnf12.affine.Propagate(precomputed_indexes[33], m103, &m105)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c211: CompressMatrix(m103, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c212: tdnnf12.relu.Propagate(NULL, m105, &m105)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c213: m107 = undefined(3328,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c214: tdnnf12.batchnorm.Propagate(NULL, m105, &m107)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c215: CompressMatrix(m105, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c216: m108 = undefined(3328,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c217: tdnnf12.dropout.Propagate(precomputed_indexes[34], m107, &m108)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c218: CompressMatrix(m107, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c219: m109 = undefined(3328,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c220: m109 = 0.66 * m100(64:3391, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c221: CompressMatrix(m100, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c222: m109 += m108
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c223: tdnnf12.noop.Propagate(NULL, m109, &m109)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c224: m112 = undefined(3264,128)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c225: m112.set(0) [dim = 3264 x 128];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c226: tdnnf13.linear.Propagate(precomputed_indexes[35], m109, &m112)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c227: m114 = undefined(3200,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c228: tdnnf13.affine.Propagate(precomputed_indexes[36], m112, &m114)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c229: CompressMatrix(m112, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c230: tdnnf13.relu.Propagate(NULL, m114, &m114)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c231: m116 = undefined(3200,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c232: tdnnf13.batchnorm.Propagate(NULL, m114, &m116)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c233: CompressMatrix(m114, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c234: m117 = undefined(3200,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c235: tdnnf13.dropout.Propagate(precomputed_indexes[37], m116, &m117)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c236: CompressMatrix(m116, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c237: m118 = undefined(3200,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c238: m118 = 0.66 * m109(64:3263, 0:1023)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c239: CompressMatrix(m109, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c240: m118 += m117
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c241: tdnnf13.noop.Propagate(NULL, m118, &m118)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c242: m120 = undefined(3200,256)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c243: m120.set(0) [dim = 3200 x 256];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c244: prefinal-l.Propagate(NULL, m118, &m120)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c245: CompressMatrix(m118, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c246: m122.swap(m117) [dim = 3200 x 1024]
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c247: prefinal-xent.affine.Propagate(NULL, m120, &m122)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c248: prefinal-xent.relu.Propagate(NULL, m122, &m122)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c249: m124 = undefined(3200,1024)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c250: prefinal-xent.batchnorm1.Propagate(NULL, m122, &m124)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c251: CompressMatrix(m122, 0, uint8, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c252: m126 = undefined(3200,256)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c253: m126.set(0) [dim = 3200 x 256];
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c254: prefinal-xent.linear.Propagate(NULL, m124, &m126)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c255: CompressMatrix(m124, 10, int16, true)
LOG (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:467) c256: prefinal-xent.batchnorm2.Propagate(NULL, m126, &m126)
ERROR (nnet3-chain-train[5.5.1009~1-e4940]:ExecuteCommand():nnet-compute.cc:471) Error running command c257: m128 = undefined(3200,3177)

[ Stack-Trace: ]
nnet3-chain-train(kaldi::MessageLogger::LogMessage() const+0xb61) [0x55ff16bcfc67]
nnet3-chain-train(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&)+0x21) [0x55ff1686858d]
nnet3-chain-train(kaldi::nnet3::NnetComputer::ExecuteCommand()+0x15be) [0x55ff16938d3a]
nnet3-chain-train(kaldi::nnet3::NnetComputer::Run()+0x178) [0x55ff16938f94]
nnet3-chain-train(kaldi::nnet3::NnetChainTrainer::TrainInternal(kaldi::nnet3::NnetChainExample const&, kaldi::nnet3::NnetComputation const&)+0x5b) [0x55ff168b9107]
nnet3-chain-train(kaldi::nnet3::NnetChainTrainer::Train(kaldi::nnet3::NnetChainExample const&)+0xe4) [0x55ff168b94b0]
nnet3-chain-train(main+0x75f) [0x55ff1686749f]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xe7) [0x7f3cdb8dac87]
nnet3-chain-train(_start+0x2a) [0x55ff16866c3a]

WARNING (nnet3-chain-train[5.5.1009~1-e4940]:Close():kaldi-io.cc:515) Pipe nnet3-chain-copy-egs                          --frame-shift=1                         ark:exp/chain_cleaned_1d/tdnn1d_sp/egs/cegs.19.ark ark:- |                         nnet3-chain-shuffle-egs --buffer-size=5000                         --srand=6 ark:- ark:- | nnet3-chain-merge-egs                         --minibatch-size=64 ark:- ark:- | had nonzero return status 36096
LOG (nnet3-chain-train[5.5.1009~1-e4940]:~NnetChainTrainer():nnet-chain-training.cc:348) Wrote computation cache to exp/chain_cleaned_1d/tdnn1d_sp/cache.7
LOG (nnet3-chain-train[5.5.1009~1-e4940]:~CachingOptimizingCompiler():nnet-optimize.cc:710) 6.6e-05 seconds taken in nnet3 compilation total (breakdown: 0 compilation, 0 optimization, 0 shortcut expansion, 0 checking, 0 computing indexes, 6.6e-05 misc.) + 0.311 I/O.
kaldi::KaldiFatalError
# Accounting: time=7 threads=1
# Ended (code 255) at Sun May 29 16:06:53 UTC 2022, elapsed time 7 seconds

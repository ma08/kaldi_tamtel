nohup: ignoring input
----------------------- Stage 9 begin---------------------------
Sun Jul 10 19:31:37 EDT 2022
steps/align_si.sh --nj 8 --cmd run.pl telugu_data/train telugu_data/lang_nosp telugu_exp/mono telugu_exp/mono_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in telugu_data/train using model from telugu_exp/mono, putting alignments in telugu_exp/mono_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang_nosp telugu_exp/mono_ali
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/mono_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
Sun Jul 10 19:32:50 EDT 2022
------------ steps/align_si.sh finished------------
Sun Jul 10 19:32:50 EDT 2022
steps/train_deltas.sh --cmd run.pl 2500 30000 telugu_data/train telugu_data/lang_nosp telugu_exp/mono_ali telugu_exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model[5.5.1035~1-3dd90]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from telugu_exp/mono_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang_nosp telugu_exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/tri1/log/analyze_alignments.log
6 warnings in telugu_exp/tri1/log/init_model.log
1 warnings in telugu_exp/tri1/log/build_tree.log
1 warnings in telugu_exp/tri1/log/questions.log
4002 warnings in telugu_exp/tri1/log/align.*.*.log
102 warnings in telugu_exp/tri1/log/update.*.log
3383 warnings in telugu_exp/tri1/log/acc.*.*.log
telugu_exp/tri1: nj=8 align prob=-96.13 over 40.11h [retry=2.6%, fail=0.2%] states=1976 gauss=30084 tree-impr=3.52
steps/train_deltas.sh: Done training system with delta+delta-delta features in telugu_exp/tri1
Sun Jul 10 19:44:02 EDT 2022
----------------------- Stage 9 end---------------------------
----------------------- Stage 10 begin---------------------------
Sun Jul 10 19:44:02 EDT 2022
tree-info telugu_exp/tri1/tree 
tree-info telugu_exp/tri1/tree 
fsttablecompose telugu_data/lang_nosp/L_disambig.fst telugu_data/lang_nosp/G.fst 
fstdeterminizestar --use-log=true 
fstminimizeencoded 
fstpushspecial 
fstisstochastic telugu_data/lang_nosp/tmp/LG.fst 
-0.0175559 -0.0185256
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=telugu_data/lang_nosp/phones/disambig.int --write-disambig-syms=telugu_data/lang_nosp/tmp/disambig_ilabels_3_1.int telugu_data/lang_nosp/tmp/ilabels_3_1.414222 telugu_data/lang_nosp/tmp/LG.fst 
fstisstochastic telugu_data/lang_nosp/tmp/CLG_3_1.fst 
0 -0.0185256
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=telugu_exp/tri1/graph_nosp/disambig_tid.int --transition-scale=1.0 telugu_data/lang_nosp/tmp/ilabels_3_1 telugu_exp/tri1/tree telugu_exp/tri1/final.mdl 
fstdeterminizestar --use-log=true 
fsttablecompose telugu_exp/tri1/graph_nosp/Ha.fst telugu_data/lang_nosp/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstrmsymbols telugu_exp/tri1/graph_nosp/disambig_tid.int 
fstrmepslocal 
fstisstochastic telugu_exp/tri1/graph_nosp/HCLGa.fst 
0.000488052 -0.0507523
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true telugu_exp/tri1/final.mdl telugu_exp/tri1/graph_nosp/HCLGa.fst 
Sun Jul 10 19:48:17 EDT 2022
----------------------- Stage 10 end---------------------------
----------------------- Stage 11 begin---------------------------
Sun Jul 10 19:48:17 EDT 2022
steps/align_si.sh --nj 8 --cmd run.pl telugu_data/train telugu_data/lang_nosp telugu_exp/tri1 telugu_exp/tri1_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in telugu_data/train using model from telugu_exp/tri1, putting alignments in telugu_exp/tri1_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang_nosp telugu_exp/tri1_ali
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/tri1_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
Sun Jul 10 19:49:53 EDT 2022
----------------------- Stage 11 mid align_si complete, train_lda starting---------------------------
Sun Jul 10 19:49:53 EDT 2022
steps/train_lda_mllt.sh --cmd run.pl 4000 50000 telugu_data/train telugu_data/lang_nosp telugu_exp/tri1_ali telugu_exp/tri2
steps/train_lda_mllt.sh: Accumulating LDA statistics.
steps/train_lda_mllt.sh: Accumulating tree stats
steps/train_lda_mllt.sh: Getting questions for tree clustering.
steps/train_lda_mllt.sh: Building the tree
steps/train_lda_mllt.sh: Initializing the model
steps/train_lda_mllt.sh: Converting alignments from telugu_exp/tri1_ali to use current tree
steps/train_lda_mllt.sh: Compiling graphs of transcripts
Training pass 1
Training pass 2
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 3
Training pass 4
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 5
Training pass 6
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang_nosp telugu_exp/tri2
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/tri2/log/analyze_alignments.log
4788 warnings in telugu_exp/tri2/log/align.*.*.log
1 warnings in telugu_exp/tri2/log/build_tree.log
7 warnings in telugu_exp/tri2/log/init_model.log
5049 warnings in telugu_exp/tri2/log/acc.*.*.log
91 warnings in telugu_exp/tri2/log/lda_acc.*.log
102 warnings in telugu_exp/tri2/log/update.*.log
telugu_exp/tri2: nj=8 align prob=-47.60 over 39.99h [retry=2.9%, fail=0.4%] states=3248 gauss=50095 tree-impr=4.13 lda-sum=15.70 mllt:impr,logdet=1.15,1.86
steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in telugu_exp/tri2
Sun Jul 10 20:04:41 EDT 2022
----------------------- Stage 11 end---------------------------
----------------------- Stage 12 begin---------------------------
Sun Jul 10 20:04:41 EDT 2022
tree-info telugu_exp/tri2/tree 
tree-info telugu_exp/tri2/tree 
make-h-transducer --disambig-syms-out=telugu_exp/tri2/graph_nosp/disambig_tid.int --transition-scale=1.0 telugu_data/lang_nosp/tmp/ilabels_3_1 telugu_exp/tri2/tree telugu_exp/tri2/final.mdl 
fstrmsymbols telugu_exp/tri2/graph_nosp/disambig_tid.int 
fstdeterminizestar --use-log=true 
fstrmepslocal 
fsttablecompose telugu_exp/tri2/graph_nosp/Ha.fst telugu_data/lang_nosp/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstisstochastic telugu_exp/tri2/graph_nosp/HCLGa.fst 
0.000487832 -0.0507523
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true telugu_exp/tri2/final.mdl telugu_exp/tri2/graph_nosp/HCLGa.fst 
Sun Jul 10 20:07:35 EDT 2022
----------------------- Stage 12 end---------------------------
----------------------- Stage 13 begin---------------------------
Sun Jul 10 20:07:35 EDT 2022
steps/get_prons.sh --cmd run.pl telugu_data/train telugu_data/lang_nosp telugu_exp/tri2
steps/get_prons.sh: telugu_exp/tri2/ali.1.gz exists, so starting from alignments.
steps/get_prons.sh: done writing prons to telugu_exp/tri2/prons.*.gz, silence counts in 
steps/get_prons.sh: telugu_exp/tri2/sil_counts_nowb.txt and pronunciation counts in 
steps/get_prons.sh: telugu_exp/tri2/pron_counts.{int,txt}
steps/get_prons.sh: ... and also in telugu_exp/tri2/pron_counts_nowb.txt
Sun Jul 10 20:07:51 EDT 2022
Checking telugu_data/local/dict_nosp/silence_phones.txt ...
--> reading telugu_data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict_nosp/silence_phones.txt is OK

Checking telugu_data/local/dict_nosp/optional_silence.txt ...
--> reading telugu_data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict_nosp/optional_silence.txt is OK

Checking telugu_data/local/dict_nosp/nonsilence_phones.txt ...
--> reading telugu_data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking telugu_data/local/dict_nosp/lexicon.txt
--> reading telugu_data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict_nosp/lexicon.txt is OK

Checking telugu_data/local/dict_nosp/lexiconp.txt
--> reading telugu_data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair telugu_data/local/dict_nosp/lexicon.txt and telugu_data/local/dict_nosp/lexiconp.txt
--> lexicon pair telugu_data/local/dict_nosp/lexicon.txt and telugu_data/local/dict_nosp/lexiconp.txt match

Checking telugu_data/local/dict_nosp/extra_questions.txt ...
--> telugu_data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory telugu_data/local/dict_nosp]

utils/dict_dir_add_pronprobs.sh: normalizing pronprobs so maximum is 1 for each word.
utils/dict_dir_add_pronprobs.sh: produced dictionary directory with probabilities in telugu_data/local/dict/
utils/dict_dir_add_pronprobs.sh: validating telugu_data/local/dict ..
Checking telugu_data/local/dict/silence_phones.txt ...
--> reading telugu_data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/silence_phones.txt is OK

Checking telugu_data/local/dict/optional_silence.txt ...
--> reading telugu_data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/optional_silence.txt is OK

Checking telugu_data/local/dict/nonsilence_phones.txt ...
--> reading telugu_data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking telugu_data/local/dict/lexicon.txt
--> reading telugu_data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/lexicon.txt is OK

Checking telugu_data/local/dict/lexiconp.txt
--> reading telugu_data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/lexiconp.txt is OK

Checking telugu_data/local/dict/lexiconp_silprob.txt
--> reading telugu_data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair telugu_data/local/dict/lexicon.txt and telugu_data/local/dict/lexiconp.txt
--> lexicon pair telugu_data/local/dict/lexicon.txt and telugu_data/local/dict/lexiconp.txt match

Checking lexicon pair telugu_data/local/dict/lexiconp.txt and telugu_data/local/dict/lexiconp_silprob.txt
--> lexicon pair telugu_data/local/dict/lexiconp.txt and telugu_data/local/dict/lexiconp_silprob.txt match

Checking telugu_data/local/dict/extra_questions.txt ...
--> telugu_data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory telugu_data/local/dict]

Some low-probability prons include: 
# sort -k2,2 -n telugu_data/local/dict/lexiconp.txt  | head -n 8
<unk> 1 NSN
అ 1 a
అం 1 a q
అంక 1 a q k a
అంకంపల్లి 1 a q k a q p a l l i
అంకంపాలెం 1 a q k a q p aa l e q
అంకాపూర్ 1 a q k aa p uu r
అంకారా 1 a q k aa r aa
Sun Jul 10 20:07:59 EDT 2022
----------------------- Stage 13 end---------------------------
----------------------- Stage 14 begin---------------------------
Sun Jul 10 20:07:59 EDT 2022
utils/prepare_lang.sh telugu_data/local/dict <unk> telugu_data/local/lang telugu_data/lang
Checking telugu_data/local/dict/silence_phones.txt ...
--> reading telugu_data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/silence_phones.txt is OK

Checking telugu_data/local/dict/optional_silence.txt ...
--> reading telugu_data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/optional_silence.txt is OK

Checking telugu_data/local/dict/nonsilence_phones.txt ...
--> reading telugu_data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking telugu_data/local/dict/lexicon.txt
--> reading telugu_data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/lexicon.txt is OK

Checking telugu_data/local/dict/lexiconp.txt
--> reading telugu_data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/lexiconp.txt is OK

Checking telugu_data/local/dict/lexiconp_silprob.txt
--> reading telugu_data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair telugu_data/local/dict/lexicon.txt and telugu_data/local/dict/lexiconp.txt
--> lexicon pair telugu_data/local/dict/lexicon.txt and telugu_data/local/dict/lexiconp.txt match

Checking lexicon pair telugu_data/local/dict/lexiconp.txt and telugu_data/local/dict/lexiconp_silprob.txt
--> lexicon pair telugu_data/local/dict/lexiconp.txt and telugu_data/local/dict/lexiconp_silprob.txt match

Checking telugu_data/local/dict/extra_questions.txt ...
--> telugu_data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory telugu_data/local/dict]

fstaddselfloops telugu_data/lang/phones/wdisambig_phones.int telugu_data/lang/phones/wdisambig_words.int 
prepare_lang.sh: validating output directory
utils/validate_lang.pl telugu_data/lang
Checking existence of separator file
separator file telugu_data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking telugu_data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> telugu_data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking telugu_data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in telugu_data/lang/phones/context_indep.txt
--> telugu_data/lang/phones/context_indep.int corresponds to telugu_data/lang/phones/context_indep.txt
--> telugu_data/lang/phones/context_indep.csl corresponds to telugu_data/lang/phones/context_indep.txt
--> telugu_data/lang/phones/context_indep.{txt, int, csl} are OK

Checking telugu_data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 204 entry/entries in telugu_data/lang/phones/nonsilence.txt
--> telugu_data/lang/phones/nonsilence.int corresponds to telugu_data/lang/phones/nonsilence.txt
--> telugu_data/lang/phones/nonsilence.csl corresponds to telugu_data/lang/phones/nonsilence.txt
--> telugu_data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking telugu_data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 10 entry/entries in telugu_data/lang/phones/silence.txt
--> telugu_data/lang/phones/silence.int corresponds to telugu_data/lang/phones/silence.txt
--> telugu_data/lang/phones/silence.csl corresponds to telugu_data/lang/phones/silence.txt
--> telugu_data/lang/phones/silence.{txt, int, csl} are OK

Checking telugu_data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in telugu_data/lang/phones/optional_silence.txt
--> telugu_data/lang/phones/optional_silence.int corresponds to telugu_data/lang/phones/optional_silence.txt
--> telugu_data/lang/phones/optional_silence.csl corresponds to telugu_data/lang/phones/optional_silence.txt
--> telugu_data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking telugu_data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 7 entry/entries in telugu_data/lang/phones/disambig.txt
--> telugu_data/lang/phones/disambig.int corresponds to telugu_data/lang/phones/disambig.txt
--> telugu_data/lang/phones/disambig.csl corresponds to telugu_data/lang/phones/disambig.txt
--> telugu_data/lang/phones/disambig.{txt, int, csl} are OK

Checking telugu_data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 53 entry/entries in telugu_data/lang/phones/roots.txt
--> telugu_data/lang/phones/roots.int corresponds to telugu_data/lang/phones/roots.txt
--> telugu_data/lang/phones/roots.{txt, int} are OK

Checking telugu_data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 53 entry/entries in telugu_data/lang/phones/sets.txt
--> telugu_data/lang/phones/sets.int corresponds to telugu_data/lang/phones/sets.txt
--> telugu_data/lang/phones/sets.{txt, int} are OK

Checking telugu_data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in telugu_data/lang/phones/extra_questions.txt
--> telugu_data/lang/phones/extra_questions.int corresponds to telugu_data/lang/phones/extra_questions.txt
--> telugu_data/lang/phones/extra_questions.{txt, int} are OK

Checking telugu_data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 214 entry/entries in telugu_data/lang/phones/word_boundary.txt
--> telugu_data/lang/phones/word_boundary.int corresponds to telugu_data/lang/phones/word_boundary.txt
--> telugu_data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading telugu_data/lang/phones/optional_silence.txt
--> telugu_data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> telugu_data/lang/phones/disambig.txt has "#0" and "#1"
--> telugu_data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> telugu_data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> telugu_data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> telugu_data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> telugu_data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 52 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 54 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking telugu_data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in telugu_data/lang/oov.txt
--> telugu_data/lang/oov.int corresponds to telugu_data/lang/oov.txt
--> telugu_data/lang/oov.{txt, int} are OK

--> telugu_data/lang/L.fst is olabel sorted
--> telugu_data/lang/L_disambig.fst is olabel sorted
--> telugu_data/lang/G.fst is ilabel sorted
--> telugu_data/lang/G.fst has 254133 states
fstdeterminizestar telugu_data/lang/G.fst /dev/null 
--> telugu_data/lang/G.fst is determinizable
--> utils/lang/check_g_properties.pl successfully validated telugu_data/lang/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> Testing determinizability of L_disambig . G
fsttablecompose telugu_data/lang/L_disambig.fst telugu_data/lang/G.fst 
fstdeterminizestar 
--> L_disambig . G is determinizable
--> SUCCESS [validating lang directory telugu_data/lang]
Sun Jul 10 20:08:55 EDT 2022
Sun Jul 10 20:08:56 EDT 2022
tree-info telugu_exp/tri2/tree 
tree-info telugu_exp/tri2/tree 
fsttablecompose telugu_data/lang/L_disambig.fst telugu_data/lang/G.fst 
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fstpushspecial 
WARNING (fstpushspecial[5.5.1035~1-3dd90]:Iterate():push-special.cc:182) push-special: finished 200 iterations without converging.  Output will be inaccurate.
fstisstochastic telugu_data/lang/tmp/LG.fst 
-0.0409736 -0.0423122
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=telugu_data/lang/phones/disambig.int --write-disambig-syms=telugu_data/lang/tmp/disambig_ilabels_3_1.int telugu_data/lang/tmp/ilabels_3_1.421619 telugu_data/lang/tmp/LG.fst 
fstisstochastic telugu_data/lang/tmp/CLG_3_1.fst 
0 -0.0423122
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=telugu_exp/tri2/graph/disambig_tid.int --transition-scale=1.0 telugu_data/lang/tmp/ilabels_3_1 telugu_exp/tri2/tree telugu_exp/tri2/final.mdl 
fsttablecompose telugu_exp/tri2/graph/Ha.fst telugu_data/lang/tmp/CLG_3_1.fst 
fstdeterminizestar --use-log=true 
fstrmepslocal 
fstminimizeencoded 
fstrmsymbols telugu_exp/tri2/graph/disambig_tid.int 
fstisstochastic telugu_exp/tri2/graph/HCLGa.fst 
0.000487832 -0.133904
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true telugu_exp/tri2/final.mdl telugu_exp/tri2/graph/HCLGa.fst 
Sun Jul 10 20:14:52 EDT 2022
----------------------- Stage 14 end---------------------------
----------------------- Stage 15 begin---------------------------
Sun Jul 10 20:14:52 EDT 2022
steps/align_si.sh --nj 8 --cmd run.pl telugu_data/train telugu_data/lang telugu_exp/tri2 telugu_exp/tri2_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in telugu_data/train using model from telugu_exp/tri2, putting alignments in telugu_exp/tri2_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang telugu_exp/tri2_ali
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/tri2_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
Sun Jul 10 20:16:36 EDT 2022
steps/train_sat.sh --cmd run.pl 5000 100000 telugu_data/train telugu_data/lang telugu_exp/tri2_ali telugu_exp/tri3
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in telugu_exp/tri2_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from telugu_exp/tri2_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang telugu_exp/tri3
analyze_phone_length_stats.py: WARNING: optional-silence SIL is seen only 77.3988716567% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/tri3/log/analyze_alignments.log
3 warnings in telugu_exp/tri3/log/est_alimdl.log
1 warnings in telugu_exp/tri3/log/build_tree.log
176356 warnings in telugu_exp/tri3/log/fmllr.*.*.log
118 warnings in telugu_exp/tri3/log/update.*.log
6067 warnings in telugu_exp/tri3/log/acc.*.*.log
1 warnings in telugu_exp/tri3/log/analyze_alignments.log
3836 warnings in telugu_exp/tri3/log/align.*.*.log
7 warnings in telugu_exp/tri3/log/init_model.log
steps/train_sat.sh: Likelihood evolution:
-50.887 -50.6399 -50.5468 -50.3015 -49.4743 -48.6281 -48.0434 -47.6137 -47.2713 -46.7336 -46.477 -46.0813 -45.8751 -45.7391 -45.6171 -45.505 -45.4007 -45.3042 -45.2141 -45.0495 -44.9322 -44.8547 -44.784 -44.718 -44.6556 -44.5962 -44.5384 -44.4818 -44.4275 -44.339 -44.2713 -44.2408 -44.2213 -44.2072 
telugu_exp/tri3: nj=8 align prob=-46.39 over 39.99h [retry=2.0%, fail=0.4%] states=4080 gauss=100088 fmllr-impr=3.16 over 31.36h tree-impr=6.60
steps/train_sat.sh: done training SAT system in telugu_exp/tri3
Sun Jul 10 20:49:54 EDT 2022
tree-info telugu_exp/tri3/tree 
tree-info telugu_exp/tri3/tree 
make-h-transducer --disambig-syms-out=telugu_exp/tri3/graph/disambig_tid.int --transition-scale=1.0 telugu_data/lang/tmp/ilabels_3_1 telugu_exp/tri3/tree telugu_exp/tri3/final.mdl 
fsttablecompose telugu_exp/tri3/graph/Ha.fst telugu_data/lang/tmp/CLG_3_1.fst 
fstdeterminizestar --use-log=true 
fstrmepslocal 
fstminimizeencoded 
fstrmsymbols telugu_exp/tri3/graph/disambig_tid.int 
fstisstochastic telugu_exp/tri3/graph/HCLGa.fst 
0.00048811 -0.133904
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true telugu_exp/tri3/final.mdl telugu_exp/tri3/graph/HCLGa.fst 
Sun Jul 10 20:53:42 EDT 2022
----------------------- Stage 15 end---------------------------
----------------------- Stage 16 begin---------------------------
Sun Jul 10 20:53:42 EDT 2022
Sun Jul 10 20:53:42 EDT 2022
steps/cleanup/clean_and_segment_data.sh: Building biased-language-model decoding graphs...
steps/cleanup/make_biased_lm_graphs.sh --nj 100 --cmd run.pl telugu_data/train telugu_data/lang telugu_exp/tri3_cleaned_work telugu_exp/tri3_cleaned_work/graphs
sym2int.pl: replacing నిర్ణయిస్తారుtem0722001981175708 with 1
** Replaced 1 instances of OOVs with 1
steps/cleanup/make_biased_lm_graphs.sh: creating utterance-group-specific decoding graphs with biased LMs
steps/cleanup/clean_and_segment_data.sh: Decoding with biased language models...
steps/cleanup/decode_segmentation.sh --beam 15.0 --nj 100 --cmd run.pl --mem 4G --transform-dir telugu_exp/tri3 --skip-scoring true --allow-partial false telugu_exp/tri3_cleaned_work/graphs telugu_data/train telugu_exp/tri3_cleaned_work/lats
steps/cleanup/decode_segmentation.sh: feature type is lda
Using fMLLR transforms from telugu_exp/tri3
steps/cleanup/decode_segmentation.sh: num-jobs for transforms mismatches, so copying them.
copy-feats ark:- ark,scp:telugu_exp/tri3_cleaned_work/lats/trans.ark,telugu_exp/tri3_cleaned_work/lats/trans.scp 
LOG (copy-feats[5.5.1035~1-3dd90]:main():copy-feats.cc:143) Copied 40440 feature matrices.
steps/diagnostic/analyze_lats.sh --cmd run.pl telugu_data/lang telugu_exp/tri3_cleaned_work/lats
analyze_phone_length_stats.py: WARNING: optional-silence SIL is seen only 76.8332916202% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_lats.sh: see stats in telugu_exp/tri3_cleaned_work/lats/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,1,1) and mean=1.1
steps/diagnostic/analyze_lats.sh: see stats in telugu_exp/tri3_cleaned_work/lats/log/analyze_lattice_depth_stats.log
steps/cleanup/clean_and_segment_data.sh: Doing oracle alignment of lattices...
lattice_oracle_align.sh: overall oracle %WER is: 1.66%
steps/cleanup/lattice_oracle_align.sh: oracle ctm is in telugu_exp/tri3_cleaned_work/lattice_oracle/ctm
align-text '--special-symbol=***' ark:telugu_exp/tri3_cleaned_work/lattice_oracle/text ark:telugu_exp/tri3_cleaned_work/lattice_oracle/oracle_hyp.txt ark,t:- 
LOG (align-text[5.5.1035~1-3dd90]:main():align-text.cc:135) Done 43951 sentences, failed for 0
utils/scoring/wer_per_utt_details.pl: Note: handling as utf-8 text
steps/cleanup/lattice_oracle_align.sh: human-readable alignments are in telugu_exp/tri3_cleaned_work/lattice_oracle/analysis/per_utt_details.txt
steps/cleanup/lattice_oracle_align.sh: per-utterance details sorted from worst to best utts are in telugu_exp/tri3_cleaned_work/lattice_oracle/all_info.sorted.txt
steps/cleanup/lattice_oracle_align.sh: format is: utt-id num-errs ref-length decoded-output (tab) reference
utils/scoring/wer_per_spk_details.pl: Note: handling as utf-8 text
utils/scoring/wer_per_spk_details.pl: Note: handling as utf-8 text
steps/cleanup/lattice_oracle_align.sh: per-speaker details are in telugu_exp/tri3_cleaned_work/lattice_oracle/analysis/per_spk_details.txt
utils/scoring/wer_ops_details.pl: Note: handling as utf-8 text
steps/cleanup/lattice_oracle_align.sh: per-word statistics [corr,sub,ins,del] are in telugu_exp/tri3_cleaned_work/lattice_oracle/analysis/ops_details.txt
steps/cleanup/lattice_oracle_align.sh: obtaining ctm edits
steps/cleanup/lattice_oracle_align.sh: ctm with edits information appended is in telugu_exp/tri3_cleaned_work/lattice_oracle/ctm_edits
steps/cleanup/clean_and_segment_data.sh: using default values of non-scored words...
steps/cleanup/clean_and_segment_data.sh: modifying ctm-edits file to allow repetitions [for dysfluencies] and 
   ... to fix reference mismatches involving non-scored words. 
   ... See telugu_exp/tri3_cleaned_work/log/modify_ctm_edits.log for details and stats, including
 a list of commonly-repeated words.
steps/cleanup/clean_and_segment_data.sh: applying 'taint' markers to ctm-edits file to mark silences and
  ... non-scored words that are next to errors.
... Stats, including global cor/ins/del/sub stats, are in telugu_exp/tri3_cleaned_work/log/taint_ctm_edits.log.
steps/cleanup/clean_and_segment_data.sh: creating segmentation from ctm-edits file.
steps/cleanup/clean_and_segment_data.sh: contents of telugu_exp/tri3_cleaned_work/log/segment_ctm_edits.log are:
# steps/cleanup/internal/segment_ctm_edits.py --oov-symbol-file=telugu_data/lang/oov.txt --ctm-edits-out=telugu_exp/tri3_cleaned_work/ctm_edits.segmented --word-stats-out=telugu_exp/tri3_cleaned_work/word_stats.txt telugu_exp/tri3_cleaned_work/non_scored_words.txt telugu_exp/tri3_cleaned_work/ctm_edits.tainted telugu_exp/tri3_cleaned_work/text telugu_exp/tri3_cleaned_work/segments 
# Started at Sun Jul 10 21:51:15 EDT 2022
#
Number of utterances is 43951, of which 1.44% had no segments after all processing; total length of data in original utterances (in seconds) was 144781
At stage  0 [segment cores], num-segments is 45718, total length 99.03% of original total 
At stage  1 [add tainted lines], num-segments is 45718, total length 99.23% of original total [+0.20%]
At stage  2 [split segments], num-segments is 45735, total length 99.23% of original total [-0.00%]
At stage  3 [truncate boundaries], num-segments is 45735, total length 96.23% of original total [-3.00%]
At stage  4 [relax boundary truncation], num-segments is 45735, total length 96.23% of original total [+0.00%]
At stage  5 [unk-padding], num-segments is 45735, total length 96.33% of original total [+0.11%]
At stage  6 [remove new segments under --min-new-segment-length, num-segments is 45202, total length 96.06% of original total [-0.27%]
At stage  7 [remove segments under --min-segment-length, num-segments is 44768, total length 95.93% of original total [-0.13%]
At stage  8 [truncate segment-starts for --max-junk-proportion, num-segments is 44768, total length 95.80% of original total [-0.12%]
At stage  9 [truncate segment-ends for --max-junk-proportion, num-segments is 44768, total length 95.71% of original total [-0.09%]
At stage 10 [remove segments without scored,non-OOV words], num-segments is 44768, total length 95.71% of original total [+0.00%]
At stage 11 [remove segments with junk exceeding --max-junk-proportion], num-segments is 44486, total length 95.28% of original total [-0.44%]
At stage 12 [merge overlapping or touching segments], num-segments is 44344, total length 95.27% of original total [-0.01%]
segment_ctm_edits.py: please see the file telugu_exp/tri3_cleaned_work/word_stats.txt for word-level statistics saying how frequently each word was excluded for a segment; format is <word> <proportion-of-time-excluded> <total-count>.  Particularly problematic words appear near the top of the file.
segment_ctm_edits.py: detailed utterance-level debug information is in telugu_exp/tri3_cleaned_work/ctm_edits.segmented
# Accounting: time=6 threads=1
# Ended (code 0) at Sun Jul 10 21:51:21 EDT 2022, elapsed time 6 seconds
For word-level statistics on p(not-being-in-a-segment), with 'worst' words at the top,
see telugu_exp/tri3_cleaned_work/word_stats.txt
For detailed utterance-level debugging information, see telugu_exp/tri3_cleaned_work/ctm_edits.segmented
steps/cleanup/clean_and_segment_data.sh: working out required segment padding to account for feature-generation edge effects.
utils/data/get_utt2dur.sh: telugu_data/train/utt2dur already exists with the expected length.  We won't recompute it.
steps/cleanup/clean_and_segment_data.sh: we'll pad segments with 0.020 seconds at segment ends to correct for feature-generation end effects
steps/cleanup/clean_and_segment_data.sh: based on the segments and text file in telugu_exp/tri3_cleaned_work/segments and telugu_exp/tri3_cleaned_work/text, creating new data-dir in telugu_data/train_cleaned
utils/data/subsegment_data_dir.sh: note: frame shift is 0.01 [affects feats.scp]
utils/data/get_utt2num_frames.sh: telugu_data/train/utt2num_frames already present!
utils/data/subsegment_data_dir.sh: warning: removing telugu_data/train_cleaned/cmvn.scp, you will have to regenerate it from the features.
utils/data/subsegment_data_dir.sh: subsegmented data from telugu_data/train to telugu_data/train_cleaned
utils/fix_data_dir.sh: filtered telugu_data/train_cleaned/wav.scp from 43951 to 43320 lines based on filter /tmp/kaldi.LMSP/recordings.
utils/fix_data_dir.sh: filtered telugu_data/train_cleaned/reco2file_and_channel from 43951 to 43320 lines based on filter /tmp/kaldi.LMSP/recordings.
utils/fix_data_dir.sh: filtered telugu_data/train_cleaned/reco2dur from 43310 to 43264 lines based on filter /tmp/kaldi.LMSP/recordings.
fix_data_dir.sh: kept all 44344 utterances.
fix_data_dir.sh: old files are kept in telugu_data/train_cleaned/.backup
steps/cleanup/clean_and_segment_data.sh: recomputing CMVN stats for the new data
steps/compute_cmvn_stats.sh telugu_data/train_cleaned telugu_data/train_cleaned/log telugu_data/train_cleaned/data
Succeeded creating CMVN stats for train_cleaned
steps/cleanup/clean_and_segment_data.sh: cleaning up intermediate files
steps/cleanup/clean_and_segment_data.sh: done.
Sun Jul 10 21:51:28 EDT 2022
Sun Jul 10 21:51:28 EDT 2022
steps/align_fmllr.sh --nj 100 --cmd run.pl telugu_data/train_cleaned telugu_data/lang telugu_exp/tri3 telugu_exp/tri3_ali_cleaned
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in telugu_data/train_cleaned using telugu_exp/tri3/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang telugu_exp/tri3_ali_cleaned
analyze_phone_length_stats.py: WARNING: optional-silence SIL is seen only 77.089460203% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/tri3_ali_cleaned/log/analyze_alignments.log
1 warnings in telugu_exp/tri3_ali_cleaned/log/analyze_alignments.log
36861 warnings in telugu_exp/tri3_ali_cleaned/log/fmllr.*.log
4764 warnings in telugu_exp/tri3_ali_cleaned/log/align_pass1.*.log
4734 warnings in telugu_exp/tri3_ali_cleaned/log/align_pass2.*.log
Sun Jul 10 21:56:11 EDT 2022
Sun Jul 10 21:56:11 EDT 2022
steps/train_sat.sh --cmd run.pl 5000 100000 telugu_data/train_cleaned telugu_data/lang telugu_exp/tri3_ali_cleaned telugu_exp/tri3_cleaned
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: Using transforms from telugu_exp/tri3_ali_cleaned
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from telugu_exp/tri3_ali_cleaned to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang telugu_exp/tri3_cleaned
analyze_phone_length_stats.py: WARNING: optional-silence SIL is seen only 74.8434683616% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/tri3_cleaned/log/analyze_alignments.log
1 warnings in telugu_exp/tri3_cleaned/log/build_tree.log
3 warnings in telugu_exp/tri3_cleaned/log/est_alimdl.log
14713 warnings in telugu_exp/tri3_cleaned/log/align.*.*.log
74170 warnings in telugu_exp/tri3_cleaned/log/acc.*.*.log
6 warnings in telugu_exp/tri3_cleaned/log/init_model.log
114 warnings in telugu_exp/tri3_cleaned/log/update.*.log
1 warnings in telugu_exp/tri3_cleaned/log/analyze_alignments.log
147486 warnings in telugu_exp/tri3_cleaned/log/fmllr.*.*.log
steps/train_sat.sh: Likelihood evolution:
-50.5587 -50.3525 -50.3164 -50.1325 -49.4089 -48.5613 -47.9741 -47.5502 -47.2236 -46.7786 -46.5449 -46.1648 -45.9912 -45.8608 -45.7398 -45.6273 -45.5228 -45.4257 -45.3353 -45.1826 -45.0714 -44.9957 -44.9267 -44.8608 -44.7974 -44.7364 -44.6772 -44.6192 -44.5623 -44.4754 -44.409 -44.3788 -44.3596 -44.3458 
telugu_exp/tri3_cleaned: nj=100 align prob=-46.58 over 36.57h [retry=5.6%, fail=4.9%] states=4088 gauss=100062 fmllr-impr=0.78 over 30.06h tree-impr=7.21
steps/train_sat.sh: done training SAT system in telugu_exp/tri3_cleaned
Sun Jul 10 22:47:08 EDT 2022
Sun Jul 10 22:47:08 EDT 2022
tree-info telugu_exp/tri3_cleaned/tree 
tree-info telugu_exp/tri3_cleaned/tree 
make-h-transducer --disambig-syms-out=telugu_exp/tri3_cleaned/graph/disambig_tid.int --transition-scale=1.0 telugu_data/lang/tmp/ilabels_3_1 telugu_exp/tri3_cleaned/tree telugu_exp/tri3_cleaned/final.mdl 
fsttablecompose telugu_exp/tri3_cleaned/graph/Ha.fst telugu_data/lang/tmp/CLG_3_1.fst 
fstdeterminizestar --use-log=true 
fstrmepslocal 
fstminimizeencoded 
fstrmsymbols telugu_exp/tri3_cleaned/graph/disambig_tid.int 
fstisstochastic telugu_exp/tri3_cleaned/graph/HCLGa.fst 
0.00048811 -0.133904
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true telugu_exp/tri3_cleaned/final.mdl telugu_exp/tri3_cleaned/graph/HCLGa.fst 
Sun Jul 10 22:51:04 EDT 2022
Sun Jul 10 22:51:04 EDT 2022
----------------------- Stage 16 end---------------------------
----------------------- Stage 17 begin---------------------------
Sun Jul 10 22:51:04 EDT 2022
local/chain/run_tdnn.sh: data_dir: telugu_data  exp_dir : telugu_exp
local/chain/run_tdnn.sh telugu_data telugu_exp
local/chain/run_tdnn.sh: running on telugu_data.
local/nnet3/run_ivector_common_telugu.sh: data_dir: telugu_data  exp_dir : telugu_exp nnet3_affix : _cleaned_1d
local/nnet3/run_ivector_common_telugu.sh: preparing directory for low-resolution speed-perturbed data (for alignment)
fix_data_dir.sh: kept all 44344 utterances.
fix_data_dir.sh: old files are kept in telugu_data/train_cleaned/.backup
utils/data/perturb_data_dir_speed_3way.sh: making sure the utt2dur and the reco2dur files are present
... in telugu_data/train_cleaned, because obtaining it after speed-perturbing
... would be very slow, and you might need them.
utils/data/get_utt2dur.sh: working out telugu_data/train_cleaned/utt2dur from telugu_data/train_cleaned/segments
utils/data/get_utt2dur.sh: computed telugu_data/train_cleaned/utt2dur
utils/data/get_reco2dur.sh: obtaining durations from recordings
utils/data/get_reco2dur.sh: could not get recording lengths from sphere-file headers, using wav-to-duration
utils/data/get_reco2dur.sh: computed telugu_data/train_cleaned/reco2dur
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in telugu_data/train_cleaned, in telugu_data/train_cleaned_sp_speed0.9
fix_data_dir.sh: kept all 44344 utterances.
fix_data_dir.sh: old files are kept in telugu_data/train_cleaned_sp_speed0.9/.backup
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/train_cleaned_sp_speed0.9
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in telugu_data/train_cleaned, in telugu_data/train_cleaned_sp_speed1.1
fix_data_dir.sh: kept all 44344 utterances.
fix_data_dir.sh: old files are kept in telugu_data/train_cleaned_sp_speed1.1/.backup
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/train_cleaned_sp_speed1.1
utils/data/combine_data.sh telugu_data/train_cleaned_sp telugu_data/train_cleaned telugu_data/train_cleaned_sp_speed0.9 telugu_data/train_cleaned_sp_speed1.1
utils/data/combine_data.sh: combined utt2uniq
utils/data/combine_data.sh: combined segments
utils/data/combine_data.sh: combined utt2spk
utils/data/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/data/combine_data.sh: combined utt2dur
utils/data/combine_data.sh [info]: **not combining utt2num_frames as it does not exist everywhere**
utils/data/combine_data.sh: combined reco2dur
utils/data/combine_data.sh [info]: **not combining feats.scp as it does not exist everywhere**
utils/data/combine_data.sh: combined text
utils/data/combine_data.sh [info]: **not combining cmvn.scp as it does not exist everywhere**
utils/data/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/data/combine_data.sh: combined reco2file_and_channel
utils/data/combine_data.sh: combined wav.scp
utils/data/combine_data.sh [info]: not combining spk2gender as it does not exist
fix_data_dir.sh: kept all 133032 utterances.
fix_data_dir.sh: old files are kept in telugu_data/train_cleaned_sp/.backup
utils/data/perturb_data_dir_speed_3way.sh: generated 3-way speed-perturbed version of data in telugu_data/train_cleaned, in telugu_data/train_cleaned_sp
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/train_cleaned_sp
utils/copy_data_dir.sh: copied data from telugu_data/train_cleaned_sp to telugu_data/train_cleaned_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/train_cleaned_sp_hires
utils/copy_data_dir.sh: copied data from telugu_data/dev to telugu_data/dev_hires
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/dev_hires
utils/copy_data_dir.sh: copied data from telugu_data/test to telugu_data/test_hires
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/test_hires
local/nnet3/run_ivector_common_telugu.sh: making MFCC features for low-resolution speed-perturbed data
steps/make_mfcc.sh --nj 15 --cmd run.pl telugu_data/train_cleaned_sp
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/train_cleaned_sp
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_cleaned_sp
steps/compute_cmvn_stats.sh telugu_data/train_cleaned_sp
Succeeded creating CMVN stats for train_cleaned_sp
local/nnet3/run_ivector_common_telugu.sh: fixing input data-dir to remove nonexistent features, in case some 
.. speed-perturbed segments were too short.
fix_data_dir.sh: kept all 133032 utterances.
fix_data_dir.sh: old files are kept in telugu_data/train_cleaned_sp/.backup
local/nnet3/run_ivector_common_telugu.sh: aligning with the perturbed low-resolution data
steps/align_fmllr.sh --nj 15 --cmd run.pl telugu_data/train_cleaned_sp telugu_data/lang telugu_exp/tri3_cleaned telugu_exp/tri3_cleaned_ali_train_cleaned_sp
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in telugu_data/train_cleaned_sp using telugu_exp/tri3_cleaned/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl telugu_data/lang telugu_exp/tri3_cleaned_ali_train_cleaned_sp
analyze_phone_length_stats.py: WARNING: optional-silence SIL is seen only 74.7453659771% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_alignments.sh: see stats in telugu_exp/tri3_cleaned_ali_train_cleaned_sp/log/analyze_alignments.log
110164 warnings in telugu_exp/tri3_cleaned_ali_train_cleaned_sp/log/fmllr.*.log
14702 warnings in telugu_exp/tri3_cleaned_ali_train_cleaned_sp/log/align_pass1.*.log
1 warnings in telugu_exp/tri3_cleaned_ali_train_cleaned_sp/log/analyze_alignments.log
14617 warnings in telugu_exp/tri3_cleaned_ali_train_cleaned_sp/log/align_pass2.*.log
local/nnet3/run_ivector_common_telugu.sh: creating high-resolution MFCC features
utils/data/perturb_data_dir_volume.sh: added volume perturbation to the data in telugu_data/train_cleaned_sp_hires
steps/make_mfcc.sh --nj 15 --mfcc-config conf/mfcc_hires.conf --cmd run.pl telugu_data/train_cleaned_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/train_cleaned_sp_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_cleaned_sp_hires
steps/compute_cmvn_stats.sh telugu_data/train_cleaned_sp_hires
Succeeded creating CMVN stats for train_cleaned_sp_hires
fix_data_dir.sh: kept all 133032 utterances.
fix_data_dir.sh: old files are kept in telugu_data/train_cleaned_sp_hires/.backup
steps/make_mfcc.sh --nj 15 --mfcc-config conf/mfcc_hires.conf --cmd run.pl telugu_data/dev_hires
steps/make_mfcc.sh: moving telugu_data/dev_hires/feats.scp to telugu_data/dev_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/dev_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for dev_hires
steps/compute_cmvn_stats.sh telugu_data/dev_hires
Succeeded creating CMVN stats for dev_hires
fix_data_dir.sh: kept all 4930 utterances.
fix_data_dir.sh: old files are kept in telugu_data/dev_hires/.backup
steps/make_mfcc.sh --nj 15 --mfcc-config conf/mfcc_hires.conf --cmd run.pl telugu_data/test_hires
steps/make_mfcc.sh: moving telugu_data/test_hires/feats.scp to telugu_data/test_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory telugu_data/test_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test_hires
steps/compute_cmvn_stats.sh telugu_data/test_hires
Succeeded creating CMVN stats for test_hires
fix_data_dir.sh: kept all 3482 utterances.
fix_data_dir.sh: old files are kept in telugu_data/test_hires/.backup
local/nnet3/run_ivector_common_telugu.sh: computing a subset of data to train the diagonal UBM.
utils/data/subset_data_dir.sh: reducing #utt from 133032 to 33258
local/nnet3/run_ivector_common_telugu.sh: computing a PCA transform from the hires data.
steps/online/nnet2/get_pca_transform.sh --cmd run.pl --splice-opts --left-context=3 --right-context=3 --max-utts 10000 --subsample 2 telugu_exp/nnet3_cleaned_1d/diag_ubm/train_cleaned_sp_hires_subset telugu_exp/nnet3_cleaned_1d/pca_transform
Done estimating PCA transform in telugu_exp/nnet3_cleaned_1d/pca_transform
local/nnet3/run_ivector_common_telugu.sh: training the diagonal UBM.
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --nj 30 --num-frames 700000 --num-threads 8 telugu_exp/nnet3_cleaned_1d/diag_ubm/train_cleaned_sp_hires_subset 512 telugu_exp/nnet3_cleaned_1d/pca_transform telugu_exp/nnet3_cleaned_1d/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory telugu_exp/nnet3_cleaned_1d/diag_ubm already exists. Backing up diagonal UBM in telugu_exp/nnet3_cleaned_1d/diag_ubm/backup.Kpu
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 700000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 30 machines, parallelized with 'run.pl'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
steps/online/nnet2/train_diag_ubm.sh: Training pass 3
local/nnet3/run_ivector_common_telugu.sh: training the iVector extractor
steps/online/nnet2/train_ivector_extractor.sh --cmd run.pl --nj 15 --num-threads 4 --num-processes 2 --online-cmvn-iextractor true telugu_data/train_cleaned_sp_hires telugu_exp/nnet3_cleaned_1d/diag_ubm telugu_exp/nnet3_cleaned_1d/extractor
steps/online/nnet2/train_ivector_extractor.sh: doing Gaussian selection and posterior computation
Accumulating stats (pass 0)
Summing accs (pass 0)
Updating model (pass 0)
Accumulating stats (pass 1)
Summing accs (pass 1)
Updating model (pass 1)
Accumulating stats (pass 2)
Summing accs (pass 2)
Updating model (pass 2)
Accumulating stats (pass 3)
Summing accs (pass 3)
Updating model (pass 3)
Accumulating stats (pass 4)
Summing accs (pass 4)
Updating model (pass 4)
Accumulating stats (pass 5)
Summing accs (pass 5)
Updating model (pass 5)
Accumulating stats (pass 6)
Summing accs (pass 6)
Updating model (pass 6)
Accumulating stats (pass 7)
Summing accs (pass 7)
Updating model (pass 7)
Accumulating stats (pass 8)
Summing accs (pass 8)
Updating model (pass 8)
Accumulating stats (pass 9)
Summing accs (pass 9)
Updating model (pass 9)
utils/data/modify_speaker_info.sh: copied data from telugu_data/train_cleaned_sp_hires to telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires/train_cleaned_sp_hires_max2, number of speakers changed from 119433 to 124788
utils/validate_data_dir.sh: Successfully validated data-directory telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires/train_cleaned_sp_hires_max2
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj 15 telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires/train_cleaned_sp_hires_max2 telugu_exp/nnet3_cleaned_1d/extractor telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires using the extractor in telugu_exp/nnet3_cleaned_1d/extractor.
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj 15 telugu_data/dev_hires telugu_exp/nnet3_cleaned_1d/extractor telugu_exp/nnet3_cleaned_1d/ivectors_dev_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to telugu_exp/nnet3_cleaned_1d/ivectors_dev_hires using the extractor in telugu_exp/nnet3_cleaned_1d/extractor.
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj 15 telugu_data/test_hires telugu_exp/nnet3_cleaned_1d/extractor telugu_exp/nnet3_cleaned_1d/ivectors_test_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to telugu_exp/nnet3_cleaned_1d/ivectors_test_hires using the extractor in telugu_exp/nnet3_cleaned_1d/extractor.
local/chain/run_tdnn.sh: creating lang directory with one state per phone.
steps/align_fmllr_lats.sh --nj 100 --cmd run.pl telugu_data/train_cleaned_sp telugu_data/lang telugu_exp/tri3_cleaned telugu_exp/chain_cleaned_1d/tri3_cleaned_train_cleaned_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in telugu_data/train_cleaned_sp using telugu_exp/tri3_cleaned/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
14816 warnings in telugu_exp/chain_cleaned_1d/tri3_cleaned_train_cleaned_sp_lats/log/align_pass1.*.log
110169 warnings in telugu_exp/chain_cleaned_1d/tri3_cleaned_train_cleaned_sp_lats/log/fmllr.*.log
2133 warnings in telugu_exp/chain_cleaned_1d/tri3_cleaned_train_cleaned_sp_lats/log/generate_lattices.*.log
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl 4000 telugu_data/train_cleaned_sp telugu_data/lang_chain telugu_exp/tri3_cleaned_ali_train_cleaned_sp telugu_exp/chain_cleaned_1d/tree_bi
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from telugu_exp/tri3_cleaned_ali_train_cleaned_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
steps/nnet3/chain/build_tree.sh: Converting alignments from telugu_exp/tri3_cleaned_ali_train_cleaned_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree
local/chain/run_tdnn.sh: creating neural net configs using the xconfig parser
tree-info telugu_exp/chain_cleaned_1d/tree_bi/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs/network.xconfig --config-dir telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs/
nnet3-init telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//init.config telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//init.raw 
LOG (nnet3-init[5.5.1035~1-3dd90]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//init.raw
nnet3-info telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//init.raw 
nnet3-init telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//ref.config telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//ref.raw 
LOG (nnet3-init[5.5.1035~1-3dd90]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//ref.raw
nnet3-info telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//ref.raw 
nnet3-init telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//ref.config telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//ref.raw 
LOG (nnet3-init[5.5.1035~1-3dd90]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//ref.raw
nnet3-info telugu_exp/chain_cleaned_1d/tdnn1d_sp/configs//ref.raw 
Mon Jul 11 02:44:15 EDT 2022
/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/libs/common.py:127: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if p.returncode is not 0:
/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/libs/common.py:147: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if p.returncode is not 0:
/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/libs/common.py:203: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if popen_object.returncode is not 0:
2022-07-11 02:44:15,927 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:35 - <module> - INFO ] Starting chain model trainer (train.py)
2022-07-11 02:44:16,044 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:284 - train - INFO ] Arguments for the experiment
{'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'chain_opts': '',
 'chunk_left_context': 0,
 'chunk_left_context_initial': -1,
 'chunk_right_context': 0,
 'chunk_right_context_final': -1,
 'chunk_width': '150,110,100',
 'cleanup': True,
 'cmvn_opts': '--config=conf/online_cmvn.conf',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl',
 'compute_per_dim_accuracy': False,
 'deriv_truncate_margin': None,
 'dir': 'telugu_exp/chain_cleaned_1d/tdnn1d_sp',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.5@0.50,0',
 'egs_command': None,
 'egs_dir': None,
 'egs_nj': 0,
 'egs_opts': '--frames-overlap-per-eg 0 --constrained false --online-cmvn true',
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'telugu_data/train_cleaned_sp_hires',
 'final_effective_lrate': 2.5e-05,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 5000000,
 'initial_effective_lrate': 0.00025,
 'input_model': None,
 'l2_regularize': 0.0,
 'lat_dir': 'telugu_exp/chain_cleaned_1d/tri3_cleaned_train_cleaned_sp_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': '64',
 'num_epochs': 6.0,
 'num_jobs_final': 12,
 'num_jobs_initial': 3,
 'num_jobs_step': 1,
 'online_ivector_dir': 'telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 1.0,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'train_opts': ['--optimization.memory-compression-level=2'],
 'tree_dir': 'telugu_exp/chain_cleaned_1d/tree_bi',
 'use_gpu': 'wait',
 'xent_regularize': 0.1}
2022-07-11 02:44:23,726 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:341 - train - INFO ] Creating phone language-model
2022-07-11 02:44:27,279 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:346 - train - INFO ] Creating denominator FST
copy-transition-model telugu_exp/chain_cleaned_1d/tree_bi/final.mdl telugu_exp/chain_cleaned_1d/tdnn1d_sp/0.trans_mdl 
LOG (copy-transition-model[5.5.1035~1-3dd90]:main():copy-transition-model.cc:62) Copied transition model.
2022-07-11 02:44:28,031 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:353 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2022-07-11 02:44:28,108 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:382 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --constrained false --online-cmvn true --cmd run.pl --cmvn-opts --config=conf/online_cmvn.conf --online-ivector-dir telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires --left-context 29 --right-context 29 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage 0 --frames-per-iter 5000000 --frames-per-eg 150,110,100 --srand 0 telugu_data/train_cleaned_sp_hires telugu_exp/chain_cleaned_1d/tdnn1d_sp telugu_exp/chain_cleaned_1d/tri3_cleaned_train_cleaned_sp_lats telugu_exp/chain_cleaned_1d/tdnn1d_sp/egs
steps/nnet3/chain/get_egs.sh: File telugu_data/train_cleaned_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 133032.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch telugu_exp/chain_cleaned_1d/tdnn1d_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn-online'
tree-info telugu_exp/chain_cleaned_1d/tdnn1d_sp/tree 
feat-to-dim scp:telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 9 archives, each with 46561 egs, with
steps/nnet3/chain/get_egs.sh:   150,110,100 labels per example, and (left,right) context = (29,29)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2022-07-11 02:47:03,165 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:431 - train - INFO ] Copying the properties from telugu_exp/chain_cleaned_1d/tdnn1d_sp/egs to telugu_exp/chain_cleaned_1d/tdnn1d_sp
2022-07-11 02:47:03,166 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:445 - train - INFO ] Computing the preconditioning matrix for input features
2022-07-11 02:47:33,765 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:454 - train - INFO ] Preparing the initial acoustic model.
2022-07-11 02:47:34,422 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:487 - train - INFO ] Training will run for 6.0 epochs = 21 iterations
2022-07-11 02:47:34,422 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/nnet3/chain/train.py:529 - train - INFO ] Iter: 0/20   Jobs: 3   Epoch: 0.00/6.0 (0.0% complete)   lr: 0.000750   
bash: line 1: 2477554 Aborted                 (core dumped) ( nnet3-chain-train --use-gpu=wait --apply-deriv-weights=False --l2-regularize=0.0 --leaky-hmm-coefficient=0.1 --xent-regularize=0.1 --print-interval=10 --momentum=0.0 --max-param-change=1.414213562373095 --backstitch-training-scale=0.0 --backstitch-training-interval=1 --l2-regularize-factor=0.3333333333333333 --optimization.memory-compression-level=2 --srand=0 "nnet3-am-copy --raw=true --learning-rate=0.00075 --scale=1.0 telugu_exp/chain_cleaned_1d/tdnn1d_sp/0.mdl - |nnet3-copy --edits='set-dropout-proportion name=* proportion=0.0' - - |" telugu_exp/chain_cleaned_1d/tdnn1d_sp/den.fst "ark,bg:nnet3-chain-copy-egs                          --frame-shift=2                         ark:telugu_exp/chain_cleaned_1d/tdnn1d_sp/egs/cegs.2.ark ark:- |                         nnet3-chain-shuffle-egs --buffer-size=5000                         --srand=0 ark:- ark:- | nnet3-chain-merge-egs                         --minibatch-size=32 ark:- ark:- |" telugu_exp/chain_cleaned_1d/tdnn1d_sp/1.2.raw ) 2>> telugu_exp/chain_cleaned_1d/tdnn1d_sp/log/train.0.2.log >> telugu_exp/chain_cleaned_1d/tdnn1d_sp/log/train.0.2.log
run.pl: job failed, log is in telugu_exp/chain_cleaned_1d/tdnn1d_sp/log/train.0.2.log
2022-07-11 02:47:57,441 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/libs/common.py:207 - background_command_waiter - ERROR ] Command exited with status 1: run.pl --gpu 1 telugu_exp/chain_cleaned_1d/tdnn1d_sp/log/train.0.2.log                     nnet3-chain-train --use-gpu=wait                      --apply-deriv-weights=False                     --l2-regularize=0.0 --leaky-hmm-coefficient=0.1                       --xent-regularize=0.1                                          --print-interval=10 --momentum=0.0                     --max-param-change=1.414213562373095                     --backstitch-training-scale=0.0                     --backstitch-training-interval=1                     --l2-regularize-factor=0.3333333333333333 --optimization.memory-compression-level=2                      --srand=0                     "nnet3-am-copy --raw=true --learning-rate=0.00075 --scale=1.0 telugu_exp/chain_cleaned_1d/tdnn1d_sp/0.mdl - |nnet3-copy --edits='set-dropout-proportion name=* proportion=0.0' - - |" telugu_exp/chain_cleaned_1d/tdnn1d_sp/den.fst                     "ark,bg:nnet3-chain-copy-egs                          --frame-shift=2                         ark:telugu_exp/chain_cleaned_1d/tdnn1d_sp/egs/cegs.2.ark ark:- |                         nnet3-chain-shuffle-egs --buffer-size=5000                         --srand=0 ark:- ark:- | nnet3-chain-merge-egs                         --minibatch-size=32 ark:- ark:- |"                     telugu_exp/chain_cleaned_1d/tdnn1d_sp/1.2.raw
bash: line 1: 2477553 Aborted                 (core dumped) ( nnet3-chain-train --use-gpu=wait --apply-deriv-weights=False --l2-regularize=0.0 --leaky-hmm-coefficient=0.1 --write-cache=telugu_exp/chain_cleaned_1d/tdnn1d_sp/cache.1 --xent-regularize=0.1 --print-interval=10 --momentum=0.0 --max-param-change=1.414213562373095 --backstitch-training-scale=0.0 --backstitch-training-interval=1 --l2-regularize-factor=0.3333333333333333 --optimization.memory-compression-level=2 --srand=0 "nnet3-am-copy --raw=true --learning-rate=0.00075 --scale=1.0 telugu_exp/chain_cleaned_1d/tdnn1d_sp/0.mdl - |nnet3-copy --edits='set-dropout-proportion name=* proportion=0.0' - - |" telugu_exp/chain_cleaned_1d/tdnn1d_sp/den.fst "ark,bg:nnet3-chain-copy-egs                          --frame-shift=1                         ark:telugu_exp/chain_cleaned_1d/tdnn1d_sp/egs/cegs.1.ark ark:- |                         nnet3-chain-shuffle-egs --buffer-size=5000                         --srand=0 ark:- ark:- | nnet3-chain-merge-egs                         --minibatch-size=32 ark:- ark:- |" telugu_exp/chain_cleaned_1d/tdnn1d_sp/1.1.raw ) 2>> telugu_exp/chain_cleaned_1d/tdnn1d_sp/log/train.0.1.log >> telugu_exp/chain_cleaned_1d/tdnn1d_sp/log/train.0.1.log
run.pl: job failed, log is in telugu_exp/chain_cleaned_1d/tdnn1d_sp/log/train.0.1.log
2022-07-11 02:48:05,492 [/rmespch_train/sourya/kaldi/egs/tamil_telugu_proj/s5_r3/steps/libs/common.py:207 - background_command_waiter - ERROR ] Command exited with status 1: run.pl --gpu 1 telugu_exp/chain_cleaned_1d/tdnn1d_sp/log/train.0.1.log                     nnet3-chain-train --use-gpu=wait                      --apply-deriv-weights=False                     --l2-regularize=0.0 --leaky-hmm-coefficient=0.1                      --write-cache=telugu_exp/chain_cleaned_1d/tdnn1d_sp/cache.1  --xent-regularize=0.1                                          --print-interval=10 --momentum=0.0                     --max-param-change=1.414213562373095                     --backstitch-training-scale=0.0                     --backstitch-training-interval=1                     --l2-regularize-factor=0.3333333333333333 --optimization.memory-compression-level=2                      --srand=0                     "nnet3-am-copy --raw=true --learning-rate=0.00075 --scale=1.0 telugu_exp/chain_cleaned_1d/tdnn1d_sp/0.mdl - |nnet3-copy --edits='set-dropout-proportion name=* proportion=0.0' - - |" telugu_exp/chain_cleaned_1d/tdnn1d_sp/den.fst                     "ark,bg:nnet3-chain-copy-egs                          --frame-shift=1                         ark:telugu_exp/chain_cleaned_1d/tdnn1d_sp/egs/cegs.1.ark ark:- |                         nnet3-chain-shuffle-egs --buffer-size=5000                         --srand=0 ark:- ark:- | nnet3-chain-merge-egs                         --minibatch-size=32 ark:- ark:- |"                     telugu_exp/chain_cleaned_1d/tdnn1d_sp/1.1.raw
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --feat.online-ivector-dir telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires --feat.cmvn-opts=--config=conf/online_cmvn.conf --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.0 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --trainer.dropout-schedule 0,0@0.20,0.5@0.50,0 --trainer.add-option=--optimization.memory-compression-level=2 --egs.dir  --egs.opts --frames-overlap-per-eg 0 --constrained false --online-cmvn true --egs.chunk-width 150,110,100 --trainer.num-chunk-per-minibatch 64 --trainer.frames-per-iter 5000000 --trainer.num-epochs 6 --trainer.optimization.num-jobs-initial 3 --trainer.optimization.num-jobs-final 12 --trainer.optimization.initial-effective-lrate 0.00025 --trainer.optimization.final-effective-lrate 0.000025 --trainer.max-param-change 2.0 --cleanup.remove-egs true --feat-dir telugu_data/train_cleaned_sp_hires --tree-dir telugu_exp/chain_cleaned_1d/tree_bi --lat-dir telugu_exp/chain_cleaned_1d/tri3_cleaned_train_cleaned_sp_lats --use-gpu=wait --dir telugu_exp/chain_cleaned_1d/tdnn1d_sp
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl', '--feat.online-ivector-dir', 'telugu_exp/nnet3_cleaned_1d/ivectors_train_cleaned_sp_hires', '--feat.cmvn-opts=--config=conf/online_cmvn.conf', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.0', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--trainer.dropout-schedule', '0,0@0.20,0.5@0.50,0', '--trainer.add-option=--optimization.memory-compression-level=2', '--egs.dir', '', '--egs.opts', '--frames-overlap-per-eg 0 --constrained false --online-cmvn true', '--egs.chunk-width', '150,110,100', '--trainer.num-chunk-per-minibatch', '64', '--trainer.frames-per-iter', '5000000', '--trainer.num-epochs', '6', '--trainer.optimization.num-jobs-initial', '3', '--trainer.optimization.num-jobs-final', '12', '--trainer.optimization.initial-effective-lrate', '0.00025', '--trainer.optimization.final-effective-lrate', '0.000025', '--trainer.max-param-change', '2.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'telugu_data/train_cleaned_sp_hires', '--tree-dir', 'telugu_exp/chain_cleaned_1d/tree_bi', '--lat-dir', 'telugu_exp/chain_cleaned_1d/tri3_cleaned_train_cleaned_sp_lats', '--use-gpu=wait', '--dir', 'telugu_exp/chain_cleaned_1d/tdnn1d_sp']

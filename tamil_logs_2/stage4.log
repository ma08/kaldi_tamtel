nohup: ignoring input
----------------------- Stage 4 begin: lang model ---------------------------
Tue Jun 21 18:18:14 UTC 2022
local/tamil_train_lm.sh 
Not installing the pocolm toolkit since it is already there.
local/tamil_train_lm.sh: Getting the Data sources
local/tamil_train_lm.sh: training the unpruned LM
lm_name wordlist_4_train-2_ted-1
unpruned_lm_dir: data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm
train_lm.py starting 
Tue Jun 21 18:18:17 UTC 2022
get_counts.py: extending min-counts from 2.0,2.0 to 2.0,2.0 since ngram order is 4
get_counts.py: extending min-counts from 1.0,1.0 to 1.0,1.0 since ngram order is 4
validate_vocab.py: validated file data/local/local_lm/data/work/int_wordlist/words.txt with 197130 entries.
validate_vocab.py: validated file data/local/local_lm/data/work/counts_wordlist_4_train-2_ted-1/words.txt with 197130 entries.
validate_count_dir.py: validated counts directory data/local/local_lm/data/work/counts_wordlist_4_train-2_ted-1
validate_vocab.py: validated file data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm/words.txt with 197130 entries.
validate_lm_dir.py: validated LM directory data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm
/home/sk5057/kaldi/egs/tamil_telugu_proj/s5_r3/../../../tools/pocolm/scripts/train_lm.py --wordlist=data/local/local_lm/data/wordlist --num-splits=10 --warm-start-ratio=20 --limit-unk-history=true --fold-dev-into=ted --bypass-metaparameter-optimization=0.854,0.0722,0.5808,0.338,0.166,0.015,0.999,0.6228,0.340,0.172,0.999,0.788,0.501,0.406 "--min-counts=train=2 ted=1" data/local/local_lm/data/text 4 data/local/local_lm/data/work data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm
train_lm.py: Getting word counts... log in data/local/local_lm/data/work/log/get_word_counts.log
train_lm.py: Getting unigram weights... log in data/local/local_lm/data/work/log/get_unigram_weights.log
train_lm.py: Generating vocab with wordlist[data/local/local_lm/data/wordlist]... log in data/local/local_lm/data/work/log/wordlist/wordlist_to_vocab.log
train_lm.py: Preparing int data... log in data/local/local_lm/data/work/log/wordlist/prepare_int_data.log
train_lm.py: Getting ngram counts... log in data/local/local_lm/data/work/log/wordlist_4_train-2_ted-1/get_counts.log
train_lm.py: Bypass optimization steps
train_lm.py: Making lm dir... log in data/local/local_lm/data/work/log/wordlist_4_train-2_ted-1/make_lm_dir.log
train_lm.py: Ngram counts: 197129 + 46048354 + 42138791 + 37115540 = 125499814
train_lm.py: Success to train lm, output dir is data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm.
train_lm.py: You may call format_arpa_lm.py to get ARPA-format lm, 
train_lm.py: Or call prune_lm_dir.py to prune the lm.
Tue Jun 21 19:05:19 UTC 2022
train_lm.py ended 
get_data_prob.py starting 
Tue Jun 21 19:05:19 UTC 2022
get_data_prob.py: log-prob of data/local/local_lm/data/real_dev_set.txt given model data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm was -7.648746912589263 per word [perplexity = 2098.0149454353095] over 109506.0 words.
Tue Jun 21 19:05:29 UTC 2022
get_data_prob.py ended 
unpruned_lm_dir: data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm
local/tamil_train_lm.sh: pruning the LM (to larger size)
Tue Jun 21 19:05:29 UTC 2022
validate_vocab.py: validated file data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm/words.txt with 197130 entries.
validate_lm_dir.py: validated LM directory data/local/local_lm/data/wordlist_4_train-2_ted-1.pocolm
float-counts-estimate: logprob per word was -5.60795 over 3.80744e+07 words.
float-counts-estimate: auxiliary function improvement per word was [ -4.42402e-11 + 2.77293e-09 + 3.60929e-09 + 2.82136e-09 ] = 9.15934e-09
float-counts-estimate 197130 data/local/local_lm/data/lm_4_prune_big/work/step0/float.all data/local/local_lm/data/lm_4_prune_big/work/step0/stats.all /dev/null /dev/null /dev/null /dev/null 
float-counts-prune 0.02 197130 data/local/local_lm/data/lm_4_prune_big/work/step0/float.all data/local/local_lm/data/lm_4_prune_big/work/step0/protected.all data/local/local_lm/data/lm_4_prune_big/work/step1/float.1 data/local/local_lm/data/lm_4_prune_big/work/step1/float.2 data/local/local_lm/data/lm_4_prune_big/work/step1/float.3 data/local/local_lm/data/lm_4_prune_big/work/step1/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step1/log/float_counts_prune.log
3.80744e+07 -2.13519e+08 -0.00168442 0.105577 0.137421 0.107422 

float-counts-prune 0.045704345703124996 197130 data/local/local_lm/data/lm_4_prune_big/work/step3/float.all data/local/local_lm/data/lm_4_prune_big/work/step3/protected.all data/local/local_lm/data/lm_4_prune_big/work/step4/float.1 data/local/local_lm/data/lm_4_prune_big/work/step4/float.2 data/local/local_lm/data/lm_4_prune_big/work/step4/float.3 data/local/local_lm/data/lm_4_prune_big/work/step4/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step4/log/float_counts_prune.log
float-counts-prune 0.09771591342985628 197130 data/local/local_lm/data/lm_4_prune_big/work/step6/float.all data/local/local_lm/data/lm_4_prune_big/work/step6/protected.all data/local/local_lm/data/lm_4_prune_big/work/step7/float.1 data/local/local_lm/data/lm_4_prune_big/work/step7/float.2 data/local/local_lm/data/lm_4_prune_big/work/step7/float.3 data/local/local_lm/data/lm_4_prune_big/work/step7/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step7/log/float_counts_prune.log
float-counts-prune 0.16534887597224948 197130 data/local/local_lm/data/lm_4_prune_big/work/step9/float.all data/local/local_lm/data/lm_4_prune_big/work/step9/protected.all data/local/local_lm/data/lm_4_prune_big/work/step10/float.1 data/local/local_lm/data/lm_4_prune_big/work/step10/float.2 data/local/local_lm/data/lm_4_prune_big/work/step10/float.3 data/local/local_lm/data/lm_4_prune_big/work/step10/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step10/log/float_counts_prune.log
float-counts-prune 0.23038233280606146 197130 data/local/local_lm/data/lm_4_prune_big/work/step12/float.all data/local/local_lm/data/lm_4_prune_big/work/step12/protected.all data/local/local_lm/data/lm_4_prune_big/work/step13/float.1 data/local/local_lm/data/lm_4_prune_big/work/step13/float.2 data/local/local_lm/data/lm_4_prune_big/work/step13/float.3 data/local/local_lm/data/lm_4_prune_big/work/step13/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step13/log/float_counts_prune.log
float-counts-prune 0.299522343206904 197130 data/local/local_lm/data/lm_4_prune_big/work/step15/float.all data/local/local_lm/data/lm_4_prune_big/work/step15/protected.all data/local/local_lm/data/lm_4_prune_big/work/step16/float.1 data/local/local_lm/data/lm_4_prune_big/work/step16/float.2 data/local/local_lm/data/lm_4_prune_big/work/step16/float.3 data/local/local_lm/data/lm_4_prune_big/work/step16/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step16/log/float_counts_prune.log
float-counts-prune 0.3583427252423175 197130 data/local/local_lm/data/lm_4_prune_big/work/step18/float.all data/local/local_lm/data/lm_4_prune_big/work/step18/protected.all data/local/local_lm/data/lm_4_prune_big/work/step19/float.1 data/local/local_lm/data/lm_4_prune_big/work/step19/float.2 data/local/local_lm/data/lm_4_prune_big/work/step19/float.3 data/local/local_lm/data/lm_4_prune_big/work/step19/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step19/log/float_counts_prune.log
validate_vocab.py: validated file data/local/local_lm/data/lm_4_prune_big/words.txt with 197130 entries.
validate_lm_dir.py: validated LM directory data/local/local_lm/data/lm_4_prune_big
float-counts-prune 0.4140494465064888 197130 data/local/local_lm/data/lm_4_prune_big/work/step21/float.all data/local/local_lm/data/lm_4_prune_big/work/step21/protected.all data/local/local_lm/data/lm_4_prune_big/work/step22/float.1 data/local/local_lm/data/lm_4_prune_big/work/step22/float.2 data/local/local_lm/data/lm_4_prune_big/work/step22/float.3 data/local/local_lm/data/lm_4_prune_big/work/step22/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step22/log/float_counts_prune.log
float-counts-prune 0.4863387801082839 197130 data/local/local_lm/data/lm_4_prune_big/work/step24/float.all data/local/local_lm/data/lm_4_prune_big/work/step24/protected.all data/local/local_lm/data/lm_4_prune_big/work/step25/float.1 data/local/local_lm/data/lm_4_prune_big/work/step25/float.2 data/local/local_lm/data/lm_4_prune_big/work/step25/float.3 data/local/local_lm/data/lm_4_prune_big/work/step25/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step25/log/float_counts_prune.log
float-counts-prune 0.5035702047819202 197130 data/local/local_lm/data/lm_4_prune_big/work/step27/float.all data/local/local_lm/data/lm_4_prune_big/work/step27/protected.all data/local/local_lm/data/lm_4_prune_big/work/step28/float.1 data/local/local_lm/data/lm_4_prune_big/work/step28/float.2 data/local/local_lm/data/lm_4_prune_big/work/step28/float.3 data/local/local_lm/data/lm_4_prune_big/work/step28/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step28/log/float_counts_prune.log
float-counts-prune 0.5622135123212209 197130 data/local/local_lm/data/lm_4_prune_big/work/step30/float.all data/local/local_lm/data/lm_4_prune_big/work/step30/protected.all data/local/local_lm/data/lm_4_prune_big/work/step31/float.1 data/local/local_lm/data/lm_4_prune_big/work/step31/float.2 data/local/local_lm/data/lm_4_prune_big/work/step31/float.3 data/local/local_lm/data/lm_4_prune_big/work/step31/float.4 2>>data/local/local_lm/data/lm_4_prune_big/work/step31/log/float_counts_prune.log
prune_lm_dir.py: Find the threshold 0.5622135123212209 in 11 iteration(s)
prune_lm_dir.py: thresholds per iter were [0.02, 0.045704345703124996, 0.09771591342985628, 0.16534887597224948, 0.23038233280606146, 0.299522343206904, 0.3583427252423175, 0.4140494465064888, 0.4863387801082839, 0.5035702047819202, 0.5622135123212209]
prune_lm_dir.py: log-prob changes per step were [-0.003991737230264955, 0.00013456606013489378, 5.57847004811632e-05, -0.014041613262454563, 0.00011656433193957095, 6.0704384048074294e-05, -0.03148414682831509, 0.00015375042022986574, 8.509981509885907e-05, -0.037251801735549345, 0.00021791156262475575, 0.0001182438068623537, -0.028040888365936167, 0.000188899549303469, 0.00010731817178996912, -0.023154192843485386, 0.00015917750509528714, 9.345988380644212e-05, -0.01600490093080915, 0.00012290820078582985, 7.488607568339883e-05, -0.013634620637488706, 0.00010219076334755111, 6.226039018343034e-05, -0.01959203559346963, 0.00013584587019099448, 7.481263000861472e-05, -0.004831724203139117, 7.321611896707499e-05, 4.756546393377178e-05, -0.011479314184859118, 5.9439321433824305e-05, 4.0334358519109945e-05]
prune_lm_dir.py: reduced number of n-grams from 125499814 to 10487328, i.e. by 91.6435509617568%
prune_lm_dir.py: approximate K-L divergence was -0.002284939384468304 + 0.20350697581577126 = 0.20122203643130293
prune_lm_dir.py: exact K-L divergence was 0.24903872418212813
Tue Jun 21 19:48:31 UTC 2022
local/tamil_train_lm.sh: pruning the LM (to larger size) ended
get_data_prob.py: log-prob of data/local/local_lm/data/real_dev_set.txt given model data/local/local_lm/data/lm_4_prune_big was -7.933330804704766 per word [perplexity = 2788.699967368008] over 109506.0 words.
local/tamil_train_lm.sh: format_arpa_lm.py started
Tue Jun 21 19:48:34 UTC 2022
validate_vocab.py: validated file data/local/local_lm/data/lm_4_prune_big/words.txt with 197130 entries.
validate_lm_dir.py: validated LM directory data/local/local_lm/data/lm_4_prune_big
float-counts-to-pre-arpa: output [ 197130 7042441 3094497 153261 ] n-grams
pre-arpa-to-arpa: success
format_arpa_lm.py: running float-counts-to-pre-arpa 4 197130 data/local/local_lm/data/lm_4_prune_big/float.all | sort  | pre-arpa-to-arpa data/local/local_lm/data/lm_4_prune_big/words.txt
format_arpa_lm.py: succeeded formatting ARPA lm from data/local/local_lm/data/lm_4_prune_big
Tue Jun 21 19:49:23 UTC 2022
local/tamil_train_lm.sh: format_arpa_lm.py ended
local/tamil_train_lm.sh: pruning the LM (to smaller size)
validate_vocab.py: validated file data/local/local_lm/data/lm_4_prune_big/words.txt with 197130 entries.
validate_lm_dir.py: validated LM directory data/local/local_lm/data/lm_4_prune_big
float-counts-estimate: logprob per word was -5.85364 over 3.80744e+07 words.
float-counts-estimate: auxiliary function improvement per word was [ 2.74614e-10 + 3.38142e-09 + 3.0509e-09 + 3.24847e-10 ] = 7.03179e-09
float-counts-estimate 197130 data/local/local_lm/data/lm_4_prune_small/work/step0/float.all data/local/local_lm/data/lm_4_prune_small/work/step0/stats.all /dev/null /dev/null /dev/null /dev/null 
float-counts-prune 0.25 197130 data/local/local_lm/data/lm_4_prune_small/work/step0/float.all data/local/local_lm/data/lm_4_prune_small/work/step0/protected.all data/local/local_lm/data/lm_4_prune_small/work/step1/float.1 data/local/local_lm/data/lm_4_prune_small/work/step1/float.2 data/local/local_lm/data/lm_4_prune_small/work/step1/float.3 data/local/local_lm/data/lm_4_prune_small/work/step1/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step1/log/float_counts_prune.log
3.80744e+07 -2.22873e+08 0.0104558 0.128746 0.116161 0.0123683 

float-counts-prune 0.5953598022460938 197130 data/local/local_lm/data/lm_4_prune_small/work/step3/float.all data/local/local_lm/data/lm_4_prune_small/work/step3/protected.all data/local/local_lm/data/lm_4_prune_small/work/step4/float.1 data/local/local_lm/data/lm_4_prune_small/work/step4/float.2 data/local/local_lm/data/lm_4_prune_small/work/step4/float.3 data/local/local_lm/data/lm_4_prune_small/work/step4/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step4/log/float_counts_prune.log
float-counts-prune 1.3562749791890383 197130 data/local/local_lm/data/lm_4_prune_small/work/step6/float.all data/local/local_lm/data/lm_4_prune_small/work/step6/protected.all data/local/local_lm/data/lm_4_prune_small/work/step7/float.1 data/local/local_lm/data/lm_4_prune_small/work/step7/float.2 data/local/local_lm/data/lm_4_prune_small/work/step7/float.3 data/local/local_lm/data/lm_4_prune_small/work/step7/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step7/log/float_counts_prune.log
float-counts-prune 1.8178174075623588 197130 data/local/local_lm/data/lm_4_prune_small/work/step9/float.all data/local/local_lm/data/lm_4_prune_small/work/step9/protected.all data/local/local_lm/data/lm_4_prune_small/work/step10/float.1 data/local/local_lm/data/lm_4_prune_small/work/step10/float.2 data/local/local_lm/data/lm_4_prune_small/work/step10/float.3 data/local/local_lm/data/lm_4_prune_small/work/step10/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step10/log/float_counts_prune.log
float-counts-prune 2.355540311966105 197130 data/local/local_lm/data/lm_4_prune_small/work/step12/float.all data/local/local_lm/data/lm_4_prune_small/work/step12/protected.all data/local/local_lm/data/lm_4_prune_small/work/step13/float.1 data/local/local_lm/data/lm_4_prune_small/work/step13/float.2 data/local/local_lm/data/lm_4_prune_small/work/step13/float.3 data/local/local_lm/data/lm_4_prune_small/work/step13/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step13/log/float_counts_prune.log
float-counts-prune 2.818338423795871 197130 data/local/local_lm/data/lm_4_prune_small/work/step15/float.all data/local/local_lm/data/lm_4_prune_small/work/step15/protected.all data/local/local_lm/data/lm_4_prune_small/work/step16/float.1 data/local/local_lm/data/lm_4_prune_small/work/step16/float.2 data/local/local_lm/data/lm_4_prune_small/work/step16/float.3 data/local/local_lm/data/lm_4_prune_small/work/step16/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step16/log/float_counts_prune.log
float-counts-prune 3.267820741995249 197130 data/local/local_lm/data/lm_4_prune_small/work/step18/float.all data/local/local_lm/data/lm_4_prune_small/work/step18/protected.all data/local/local_lm/data/lm_4_prune_small/work/step19/float.1 data/local/local_lm/data/lm_4_prune_small/work/step19/float.2 data/local/local_lm/data/lm_4_prune_small/work/step19/float.3 data/local/local_lm/data/lm_4_prune_small/work/step19/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step19/log/float_counts_prune.log
validate_vocab.py: validated file data/local/local_lm/data/lm_4_prune_small/words.txt with 197130 entries.
validate_lm_dir.py: validated LM directory data/local/local_lm/data/lm_4_prune_small
float-counts-prune 3.74141939628405 197130 data/local/local_lm/data/lm_4_prune_small/work/step21/float.all data/local/local_lm/data/lm_4_prune_small/work/step21/protected.all data/local/local_lm/data/lm_4_prune_small/work/step22/float.1 data/local/local_lm/data/lm_4_prune_small/work/step22/float.2 data/local/local_lm/data/lm_4_prune_small/work/step22/float.3 data/local/local_lm/data/lm_4_prune_small/work/step22/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step22/log/float_counts_prune.log
float-counts-prune 3.9935267579477207 197130 data/local/local_lm/data/lm_4_prune_small/work/step24/float.all data/local/local_lm/data/lm_4_prune_small/work/step24/protected.all data/local/local_lm/data/lm_4_prune_small/work/step25/float.1 data/local/local_lm/data/lm_4_prune_small/work/step25/float.2 data/local/local_lm/data/lm_4_prune_small/work/step25/float.3 data/local/local_lm/data/lm_4_prune_small/work/step25/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step25/log/float_counts_prune.log
float-counts-prune 4.395341263592057 197130 data/local/local_lm/data/lm_4_prune_small/work/step27/float.all data/local/local_lm/data/lm_4_prune_small/work/step27/protected.all data/local/local_lm/data/lm_4_prune_small/work/step28/float.1 data/local/local_lm/data/lm_4_prune_small/work/step28/float.2 data/local/local_lm/data/lm_4_prune_small/work/step28/float.3 data/local/local_lm/data/lm_4_prune_small/work/step28/float.4 2>>data/local/local_lm/data/lm_4_prune_small/work/step28/log/float_counts_prune.log
prune_lm_dir.py: Find the threshold 4.395341263592057 in 10 iteration(s)
prune_lm_dir.py: thresholds per iter were [0.25, 0.5953598022460938, 1.3562749791890383, 1.8178174075623588, 2.355540311966105, 2.818338423795871, 3.267820741995249, 3.74141939628405, 3.9935267579477207, 4.395341263592057]
prune_lm_dir.py: log-prob changes per step were [-5.864701741852793e-05, 6.236672147164499e-08, 1.987120243523207e-08, -0.006583084697329439, 5.088761740171873e-06, 2.2800868825247408e-06, -0.0927828146996407, 0.0001351946557266825, 5.868317294560124e-05, -0.04974208391990419, 0.0001575247567919652, 8.64275050952871e-05, -0.0405366860672788, 0.00014095095917466855, 9.163527724665392e-05, -0.028840375685499967, 0.0001533791182526842, 0.0001092322662996659, -0.02736142920177337, 0.00019780668112957787, 0.00014620861523753493, -0.024503130712499738, 0.0002165593023133654, 0.00016345243076712964, -0.012459789254722332, 0.00023035349998949423, 0.0001753866645304982, -0.030481373311201227, 0.0002614561148698338, 0.0001952939951778623]
prune_lm_dir.py: reduced number of n-grams from 10487328 to 1941684, i.e. by 81.48542698387998%
prune_lm_dir.py: approximate K-L divergence was -0.0025269961020951085 + 0.3133494145672683 = 0.31082241846517317
prune_lm_dir.py: exact K-L divergence was 0.31107515811148634
get_data_prob.py: log-prob of data/local/local_lm/data/real_dev_set.txt given model data/local/local_lm/data/lm_4_prune_small was -8.407367528719888 per word [perplexity = 4479.951631093753] over 109506.0 words.
validate_vocab.py: validated file data/local/local_lm/data/lm_4_prune_small/words.txt with 197130 entries.
validate_lm_dir.py: validated LM directory data/local/local_lm/data/lm_4_prune_small
float-counts-to-pre-arpa: output [ 197130 1498968 240318 5269 ] n-grams
pre-arpa-to-arpa: success
format_arpa_lm.py: running float-counts-to-pre-arpa 4 197130 data/local/local_lm/data/lm_4_prune_small/float.all | sort  | pre-arpa-to-arpa data/local/local_lm/data/lm_4_prune_small/words.txt
format_arpa_lm.py: succeeded formatting ARPA lm from data/local/local_lm/data/lm_4_prune_small
Tue Jun 21 19:53:32 UTC 2022
----------------------- Stage 4 end: lang model ---------------------------
